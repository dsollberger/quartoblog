{
  "hash": "ad61e23f00f738b068637defff8727cf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Sentiment Analysis of The Office\"\nauthor: \"Derek Sollberger\"\ndate: \"2024-07-03\"\nexecute:\n  cache: true\nformat: html\n---\n\n\nThis summer, I am mentoring some high school students through their data science projects. For a data set, I am suggesting the repository of scripts from the TV show The Office through the `schrute` package, but with sentiment scores attached to the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"dplyr\")\nlibrary(\"schrute\")\nlibrary(\"sentiment.ai\")\nlibrary(\"SentimentAnalysis\")\nlibrary(\"sentimentr\")\nlibrary(\"SnowballC\")\nlibrary(\"syuzhet\")\n```\n:::\n\n\n## Loading the Data\n\nFollowing the [documentation](https://cran.r-project.org/web/packages/schrute/vignettes/theoffice.html) at the `schrute` package, we can get copy of the episode scripts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscript_data <- schrute::theoffice\ncolnames(script_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"index\"            \"season\"           \"episode\"          \"episode_name\"    \n [5] \"director\"         \"writer\"           \"character\"        \"text\"            \n [9] \"text_w_direction\" \"imdb_rating\"      \"total_votes\"      \"air_date\"        \n```\n\n\n:::\n:::\n\n## Computing Sentiment Scores\n\nFollowing the [documentation](https://cran.r-project.org/web/packages/sentiment.ai/readme/README.html) at the `sentiment.ai` package, we can compute sentiment scores for each `text` (please refer to the 3 sentiment packages for more information.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_time <- Sys.time()\nsentimentr_score <- sentimentr::sentiment_by(\n  get_sentences(script_data$text), 1:length(script_data$text))$ave_sentiment\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Each time `sentiment_by` is run it has to do sentence boundary disambiguation when a\nraw `character` vector is passed to `text.var`. This may be costly of time and\nmemory.  It is highly recommended that the user first runs the raw `character`\nvector through the `get_sentences` function.\n```\n\n\n:::\n\n```{.r .cell-code}\n# computation time\nend_time <- Sys.time()\nend_time - start_time\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime difference of 31.93237 secs\n```\n\n\n:::\n\n```{.r .cell-code}\n# for some reason, this computation created one extra number\nsentimentr_score <- sentimentr_score[-length(sentimentr_score)]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_time <- Sys.time()\nsentimentAnalysis_score <- SentimentAnalysis::analyzeSentiment(script_data$text)$SentimentQDAP\n\n# computation time\nend_time <- Sys.time()\nend_time - start_time\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime difference of 2.729575 mins\n```\n\n\n:::\n:::\n\nThis code for the `sentiment.ai` package isn't working for me at the moment; I might return to it later.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initiate the model\n# This will create the sentiment.ai.embed model\n# Do this so it can be reused without recompiling - especially on GPU!\n\n# run once overall\n# sentiment.ai::install_sentiment.ai() \n\n# run once per session\nsentiment.ai::init_sentiment.ai()\n\nstart_time <- Sys.time()\nsentiment_ai_score <- sentiment.ai::sentiment_score(script_data$text)\n\n# computation time\nend_time <- Sys.time()\nend_time - start_time\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_time <- Sys.time()\nsyuzhet_score <- syuzhet::get_sentiment(script_data$text)\n\n# computation time\nend_time <- Sys.time()\nend_time - start_time\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime difference of 16.43901 secs\n```\n\n\n:::\n:::\n\n\n## Combining the Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\noffice_sentiment <- cbind(script_data,\n                          sentimentAnalysis_score,\n                          sentimentr_score,\n                          syuzhet_score)\n```\n:::\n\n\nHere is a glimpse of the data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20240703)\noffice_sentiment |>\n  dplyr::select(episode, character,\n                sentimentAnalysis_score,\n                sentimentr_score,\n                syuzhet_score, \n                text) |>\n  dplyr::slice_sample(n = 10) |>\n  dplyr::as_tibble()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 6\n   episode character sentimentAnalysis_sc…¹ sentimentr_score syuzhet_score text \n     <int> <chr>                      <dbl>            <dbl>         <dbl> <chr>\n 1       5 Darryl                     0               0.447           0    You'…\n 2       8 Andy                      -0.167           0.409          -0.4  Our …\n 3       5 Andy                      -0.1             0.0559          0.25 Knoc…\n 4      11 Michael                    0.286           0.924           2.25 Just…\n 5      15 Dwight                     0.25           -0.144           0    Impo…\n 6      13 Michael                    0               0               0    Heee…\n 7      24 Andy                       0.25            0               0    Erin…\n 8       5 Pam                        0.333           0.262           0    Come…\n 9       5 Phyllis                    0.5             0.424           0.5  That…\n10      14 Jim                       -0.2             0.8            -0.5  That…\n# ℹ abbreviated name: ¹​sentimentAnalysis_score\n```\n\n\n:::\n:::\n\n\n## Saving the Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreadr::write_csv(office_sentiment, \"office_sentiment.csv\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}