{
  "hash": "121ff64e7f0d24296d00cf9d5ee120d5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Linear Discriminant Analysis\"\nauthor: \"Derek Sollberger\"\ndate: \"2024-05-19\"\nformat: html\n---\n\n\nToday, I am trying to replicate Figure 9.4 in *Probabilistic Machine Learning* by Kevin Murphy.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"dplyr\")\nlibrary(\"ggplot2\")\nlibrary(\"ggtext\")\nlibrary(\"palmerpenguins\")\n\nadelie_color = \"#fb7504\"\nchinstrap_color = \"#c65ccc\"\ngentoo_color = \"#067476\"\n```\n:::\n\n\n## Data\n\nInstead of the gender data, I will run classification on the Palmer Penguin data. Today's experiments will be for classification between two classes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_2_class <- penguins |>\n  filter(species %in% c(\"Chinstrap\", \"Gentoo\")) |>\n  na.omit()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_2_class |>\nggplot(aes(x = flipper_length_mm, y = bill_length_mm, \n           color = species)) + \n  geom_point(size = 3) + \n  labs(title = \"Two Predictor Variables\",\n       subtitle = \"50mm-long bill and 195mm-long flipper\",\n       caption = \"Derek Sollberger\") +\n  scale_color_manual(values = c(chinstrap_color, gentoo_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n```\n\n::: {.cell-output-display}\n![](lda_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_set <- penguin_2_class |>\n  select(flipper_length_mm, bill_length_mm)\n```\n:::\n\n\n## Principal Component Analysis\n\nDimensionality reduction via principal component analysis (PCA) is available in base R.\n\n* blog post: [https://www.r-bloggers.com/2021/05/principal-component-analysis-pca-in-r/](https://www.r-bloggers.com/2021/05/principal-component-analysis-pca-in-r/)\n\n\n::: {.cell}\n\n```{.r .cell-code}\npca_results <- prcomp(train_set, center = TRUE, scale. = TRUE)\n```\n:::\n\n\nHere is some algebra to find a line parallel to the first principal component (and goes through the centroid)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndel_x <- pca_results$rotation[1,1]\ndel_y <- pca_results$rotation[2,1]\npca_slope <- del_y / del_x\n\nxbar <- mean(train_set$flipper_length_mm, na.rm = TRUE)\nybar <- mean(train_set$bill_length_mm, na.rm = TRUE)\npca_intercept <- ybar - pca_slope * xbar\n```\n:::\n\n\nHere is a visualization of PC1, the first principal component direction.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_2_class |>\nggplot(aes(x = flipper_length_mm, y = bill_length_mm)) + \n  geom_point(size = 3) + \n  geom_abline(slope = pca_slope, intercept = pca_intercept,\n              color = adelie_color, linewidth = 3) +\n  labs(title = \"Principal Component Analysis\",\n       subtitle = \"<span style = 'color:#fb7504'>first principal component</span>\",\n       caption = \"Derek Sollberger\") +\n  # scale_color_manual(values = c(chinstrap_color, gentoo_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n```\n\n::: {.cell-output-display}\n![](lda_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nNow, we can project the data down into the one-dimensional space using matrix multiplication.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_mat <- as.matrix(train_set)\nproj_mat  <- as.matrix(pca_results$rotation[,1])\nprojection_data <- train_mat %*% proj_mat\nprojection_df <- cbind(penguin_2_class, projection_data)\n```\n:::\n\n\nFinally, let us look at the classification in the PC1 dimension.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprojection_df |>\n  ggplot(aes(x = projection_data)) +\n  geom_density(aes(fill = species),\n               alpha = 0.5) + \n  labs(title = \"Classification via <br><span style = 'color:#fb7504'>Principal Component Analysis</span>\",\n       subtitle = \"\",\n       caption = \"Derek Sollberger\",\n       x = \"(PC1) first principal component\",\n       y = \"\") +\n  scale_fill_manual(values = c(chinstrap_color, gentoo_color)) +\n  theme_minimal() +\n  theme(axis.title.y  = element_blank(),\n        axis.text.y   = element_blank(),\n        axis.ticks.y  = element_blank(),\n        plot.title    = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n```\n\n::: {.cell-output-display}\n![](lda_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n## Linear Discriminant Analysis\n\nDimensionality reduction via linear discriminant analysis (LDA) is available in the `MASS` package.\n\n* blog post: [http://www.sthda.com/english/articles/36-classification-methods-essentials/146-discriminant-analysis-essentials-in-r/](http://www.sthda.com/english/articles/36-classification-methods-essentials/146-discriminant-analysis-essentials-in-r/)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlda_model <- MASS::lda(bill_length_mm ~ flipper_length_mm, data = \n                         train_set)\n```\n:::\n\n\nHere is some algebra to find a line parallel to the first linear discriminant (and goes through the centroid)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndel_x <- 1\ndel_y <- lda_model$scaling[1,1]\nlda_slope <- del_y / del_x\n\nxbar <- mean(train_set$flipper_length_mm, na.rm = TRUE)\nybar <- mean(train_set$bill_length_mm, na.rm = TRUE)\nlda_intercept <- ybar - lda_slope * xbar\n```\n:::\n\n\nHere is a visualization of LDA1, the first linear discriminant.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_2_class |>\nggplot(aes(x = flipper_length_mm, y = bill_length_mm, \n           color = species)) + \n  geom_point(size = 3) + \n  geom_abline(slope = lda_slope, intercept = lda_intercept,\n              color = adelie_color, linewidth = 3) +\n  labs(title = \"Linear Discriminant Analysis\",\n       subtitle = \"<span style = 'color:#fb7504'>first linear discriminant</span>\",\n       caption = \"Derek Sollberger\") +\n  scale_color_manual(values = c(chinstrap_color, gentoo_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n```\n\n::: {.cell-output-display}\n![](lda_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nNow, we can project the data down into the one-dimensional space using matrix multiplication.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_mat <- as.matrix(train_set)\nproj_mat  <- as.matrix(c(1, lda_model$scaling[1,1]))\nprojection_data <- train_mat %*% proj_mat\nprojection_df <- cbind(penguin_2_class, projection_data)\n```\n:::\n\n\nFinally, let us look at the classification in the first linear discriminant.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprojection_df |>\n  ggplot(aes(x = projection_data)) +\n  geom_density(aes(fill = species),\n               alpha = 0.5) + \n  labs(title = \"Classification via <br><span style = 'color:#fb7504'>Linear Discriminant Analysis</span>\",\n       subtitle = \"\",\n       caption = \"Derek Sollberger\",\n       x = \"(LDA1) first linear discriminant\",\n       y = \"\") +\n  scale_fill_manual(values = c(chinstrap_color, gentoo_color)) +\n  theme_minimal() +\n  theme(axis.title.y  = element_blank(),\n        axis.text.y   = element_blank(),\n        axis.ticks.y  = element_blank(),\n        plot.title    = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n```\n\n::: {.cell-output-display}\n![](lda_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "lda_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}