[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "quartoblog",
    "section": "",
    "text": "hospital_data\n\n\n\n\n\n\n\n\n\n\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHW1\n\n\n\n\n\n\n\n\n\n\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\nSpherical Geometries\n\n\n\n\n\n\n\n\n\n\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\ngraphviz\n\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\nSex in a Biological Context\n\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2023\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\nMath Biology Video Project\n\n\n\n\n\n\n\n\n\n\n\n\nApr 3, 2023\n\n\nDerek Sollberger, Emily Weigel\n\n\n\n\n\n\n  \n\n\n\n\nJupyterHub Showcase\n\n\n\n\n\n\n\n\n\n\n\n\nMar 6, 2023\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncurly operator\n\n\n\n\n\n\n\n\n\n\n\n\nJan 15, 2023\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStardew Valley Crops\n\n\n\n\n\n\n\n\n\n\n\n\nJan 13, 2023\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCanvas_Roster\n\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeasons Greetings by Riinu Pius\n\n\n\n\n\n\n\n\n\n\n\n\nDec 22, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\nAnyway Heres Wonderwall\n\n\n\n\n\n\n\n\n\n\n\n\nSep 29, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPatchwork\n\n\n\n\n\n\n\n\n\n\n\n\nSep 27, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\nSettlement Survival Start\n\n\n\n\n\n\n\n\n\n\n\n\nSep 3, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\nCoefficient of Variation\n\n\n\n\n\n\n\n\n\n\n\n\nSep 2, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\nIntentional Walks\n\n\n\n\n\n\n\nbaseball\n\n\n\n\n\n\n\n\n\n\n\nAug 26, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\nOblicubes\n\n\n\n\n\n\n\nfonts\n\n\n\n\n\n\n\n\n\n\n\nAug 15, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\nTypewriter\n\n\n\n\n\n\n\nvisualization\n\n\n\n\n\n\n\n\n\n\n\nAug 14, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\nBump\n\n\n\n\n\n\n\nsports\n\n\n\n\n\n\n\n\n\n\n\nAug 12, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\noverviewR\n\n\n\n\n\n\n\nexploratory data analysis\n\n\n\n\n\n\n\n\n\n\n\nAug 12, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nquarto\n\n\n\n\n\n\n\n\n\n\n\nAug 12, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalifornia Weather\n\n\n\n\n\n\n\n\n\n\n\n\nJan 25, 2022\n\n\nDerek Sollberger\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Today I followed Albert Rapp’s guide to creating a Quarto blog.\nFor me, it was a matter of making\n\na GitHub repository, called it quartoblog, and cloned it to my computer\ndeleted the quartoblog folder on my computer\nstarted a new project in RStudio to select Quarto web site (note that Quarto is already bundled in newer versions of the RStudio IDE)\ngot Netlify and GitHub to play nicely with each other and share the quartoblog repository\nupdated my domain redirect to the Netlify site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/bump/bump.html",
    "href": "posts/bump/bump.html",
    "title": "Bump",
    "section": "",
    "text": "library(\"ggbump\")\nlibrary(\"Lahman\")\nlibrary(\"tidyverse\")\n\nFor today’s easy foray, let us seek out the wins and losses of teams in the Teams data frame (I tend to call my data frames df for typing ease).\n\ndf <- Teams\n\nThere are about 3000 observations and 48 variables. I will need some of the column names.\n\ncolnames(df)\n\n [1] \"yearID\"         \"lgID\"           \"teamID\"         \"franchID\"      \n [5] \"divID\"          \"Rank\"           \"G\"              \"Ghome\"         \n [9] \"W\"              \"L\"              \"DivWin\"         \"WCWin\"         \n[13] \"LgWin\"          \"WSWin\"          \"R\"              \"AB\"            \n[17] \"H\"              \"X2B\"            \"X3B\"            \"HR\"            \n[21] \"BB\"             \"SO\"             \"SB\"             \"CS\"            \n[25] \"HBP\"            \"SF\"             \"RA\"             \"ER\"            \n[29] \"ERA\"            \"CG\"             \"SHO\"            \"SV\"            \n[33] \"IPouts\"         \"HA\"             \"HRA\"            \"BBA\"           \n[37] \"SOA\"            \"E\"              \"DP\"             \"FP\"            \n[41] \"name\"           \"park\"           \"attendance\"     \"BPF\"           \n[45] \"PPF\"            \"teamIDBR\"       \"teamIDlahman45\" \"teamIDretro\"   \n\n\nTo make a quick exploration, let us filter for the past 10 seasons of baseball (2012 to 2021) and select the columns I will use later.\n\ndf <- Teams |>\n  filter(yearID >= 2012) |>\n  select(yearID, lgID, franchID, divID, Rank)\nhead(df)\n\n  yearID lgID franchID divID Rank\n1   2012   NL      ARI     W    3\n2   2012   NL      ATL     E    2\n3   2012   AL      BAL     E    2\n4   2012   AL      BOS     E    5\n5   2012   AL      CHW     C    2\n6   2012   NL      CHC     C    5\n\n\nTo be honest, I thought I was going to have to code up some function to rank team wins within the MLB divisions, but the Lahman database already has that!\n\ndf_left <- df |> filter(yearID == 2012 & lgID == \"NL\")\ndf_right <- df |> filter(yearID == 2021 & lgID == \"NL\")\n\n\ndf |>\n  filter(lgID == \"NL\") |>\n  ggplot(aes(x = yearID, y = -Rank, color = franchID)) +\n  geom_bump(size = 2) +\n  geom_point(aes(x = yearID, y = -Rank, color = franchID),\n             size = 5) +\n  geom_label(aes(x = yearID, y = -Rank, label = franchID), data = df_left) +\n  geom_label(aes(x = yearID, y = -Rank, label = franchID), data = df_right) +\n  facet_wrap(. ~ divID, ncol = 1) +\n  labs(title = \"National League Standings\",\n       subtitle = \"early draft of bump plot\",\n       caption = \"Derek Sollberger\") +\n  theme(legend.position = \"none\",\n        panel.background = element_blank())\n\nWarning in f(...): 'StatBump' needs at least two observations per group\n\n\n\n\n\n\n\n\nbump plot"
  },
  {
    "objectID": "posts/typewriter/typewriter.html",
    "href": "posts/typewriter/typewriter.html",
    "title": "Typewriter",
    "section": "",
    "text": "library(\"gt\")\n\n\ndf <- data.frame(\n  Period = c(\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"),\n  Course = c(\"Academic Decathlon\", \"Spanish 4 AP\", \"Calculus AP BC\", \"English 3 Honors\", \"Computer Applications\", \"Physics AP\", \"US History\")\n)\n\n\n# https://gt.rstudio.com/reference/cell_borders.html\ndf |>\n  gt() |>\n  tab_options(\n    # table.background.color = \"#E8EBE6\",\n    table.font.names = \"Courier New\"\n  ) |>\n  tab_style(\n    locations = cells_body(\n      columns = everything(),\n      rows = everything()\n    ),\n    style = list(\n      cell_borders(\n        sides = c(\"top\", \"bottom\"),\n        color = \"cyan\",\n        style = \"solid\"\n      ),\n      cell_fill(color = \"#E8EBE6\") #https://www.crispedge.com/color/e8ebe6/\n    )\n  ) |>\n  tab_style(\n    locations = cells_body(\n      columns = \"Course\",\n      rows = everything()\n    ),\n    style = list(\n      cell_borders(\n        sides = c(\"left\"),\n        color = \"red\",\n        style = \"solid\"\n      ),\n      cell_fill(color = \"#E8EBE6\")\n    )\n  )\n\n\n\n\n\n  \n  \n    \n      Period\n      Course\n    \n  \n  \n    0\nAcademic Decathlon\n    1\nSpanish 4 AP\n    2\nCalculus AP BC\n    3\nEnglish 3 Honors\n    4\nComputer Applications\n    5\nPhysics AP\n    6\nUS History\n  \n  \n  \n\n\n\n\n\n\n\nhigh school junior year schedule"
  },
  {
    "objectID": "posts/overviewR/overviewR.html",
    "href": "posts/overviewR/overviewR.html",
    "title": "overviewR",
    "section": "",
    "text": "Today I wanted to try out the overviewR package.\n\ncheat sheet: https://github.com/cosimameyer/overviewR/blob/master/man/figures/CheatSheet_overviewR.pdf\n\n\nlibrary(\"overviewR\")\nlibrary(\"palmerpenguins\")\n\nAt this moment, I misread what overviewR does (I thought it would summarize everything). Instead, I will just try out one tool for now.\n\npenguins_raw |>\n  overview_na()"
  },
  {
    "objectID": "posts/oblicubes/oblicubes.html",
    "href": "posts/oblicubes/oblicubes.html",
    "title": "Oblicubes",
    "section": "",
    "text": "https://github.com/trevorld/oblicubes\n\n\nlibrary(\"bittermelon\")\n\n\nAttaching package: 'bittermelon'\n\n\nThe following object is masked from 'package:base':\n\n    which\n\nlibrary(\"grid\")\nlibrary(\"oblicubes\")\n\n\n# example from\n# https://github.com/trevorld/oblicubes\nfont_file <- system.file(\"fonts/spleen/spleen-8x16.hex.gz\", package = \"bittermelon\")\nfont <- read_hex(font_file)\nbml <- as_bm_list(\"RSTATS\", font = font)\n# Add a shadow effect and border\nbm <- (3 * bml) |>\n  bm_pad(sides = 2L) |>\n  bm_shadow(value = 2L) |>\n  bm_call(cbind) |>\n  bm_extend(sides = 1L, value = 1L)\ncol <- apply(bm + 1L, c(1, 2), function(i) {\n  switch(i, \"white\", \"grey20\", \"lightblue\", \"darkblue\")\n})\ncoords <- xyz_heightmap(bm, col = col, flipy=FALSE)\ngrid.oblicubes(coords, width=unit(2.2, \"mm\"))\n\n\n\n\n\n# Bio 18\nbml <- as_bm_list(\"BIO 18\", font = font)\n\nbm <- (3 * bml) |>\n  bm_pad(sides = 2L) |>\n  bm_shadow(value = 2L) |>\n  bm_call(cbind) |>\n  bm_extend(sides = 1L, value = 1L)\ncol <- apply(bm + 1L, c(1, 2), function(i) {\n  switch(i, \"white\", \"#5b5b5b\", \"#DAA900\", \"#002856\")\n  # switch(i, \"#DAA900\", \"#5b5b5b\", \"#0091b3\", \"#002856\")\n})\ncoords <- xyz_heightmap(bm, col = col, flipy=FALSE)\ngrid.oblicubes(coords, width=unit(2.2, \"mm\"))\n\n\n\n\n\n# Math 32\nbml <- as_bm_list(\"MATH32\", font = font)\n\nbm <- (3 * bml) |>\n  bm_pad(sides = 2L) |>\n  bm_shadow(value = 2L) |>\n  bm_call(cbind) |>\n  bm_extend(sides = 1L, value = 1L)\ncol <- apply(bm + 1L, c(1, 2), function(i) {\n  switch(i, \"white\", \"#5b5b5b\", \"#DAA900\", \"#002856\")\n  # switch(i, \"#DAA900\", \"#5b5b5b\", \"#0091b3\", \"#002856\")\n})\ncoords <- xyz_heightmap(bm, col = col, flipy=FALSE)\ngrid.oblicubes(coords, width=unit(2.2, \"mm\"))\n\n\n\n\n\n# Spark\nbml <- as_bm_list(\"SPORTS\", font = font)\n\nbm <- (3 * bml) |>\n  bm_pad(sides = 2L) |>\n  bm_shadow(value = 2L) |>\n  bm_call(cbind) |>\n  bm_extend(sides = 1L, value = 1L)\ncol <- apply(bm + 1L, c(1, 2), function(i) {\n  switch(i, \"white\", \"#5b5b5b\", \"#DAA900\", \"#002856\")\n  # switch(i, \"#DAA900\", \"#5b5b5b\", \"#0091b3\", \"#002856\")\n})\ncoords <- xyz_heightmap(bm, col = col, flipy=FALSE)\ngrid.oblicubes(coords, width=unit(2.2, \"mm\"))\n\n\n\n\nand then I cropped an resized each image to 262 by 146 pixels\n\nhttps://unomaha.instructure.com/courses/33506/pages/create-a-canvas-dashboard-image-for-your-course"
  },
  {
    "objectID": "posts/oblicubes.html",
    "href": "posts/oblicubes.html",
    "title": "Oblicubes",
    "section": "",
    "text": "https://github.com/trevorld/oblicubes\n\n\nlibrary(\"bittermelon\")\n\n\nAttaching package: 'bittermelon'\n\n\nThe following object is masked from 'package:base':\n\n    which\n\nlibrary(\"grid\")\nlibrary(\"oblicubes\")\n\n\n# example from\n# https://github.com/trevorld/oblicubes\nfont_file <- system.file(\"fonts/spleen/spleen-8x16.hex.gz\", package = \"bittermelon\")\nfont <- read_hex(font_file)\nbml <- as_bm_list(\"RSTATS\", font = font)\n# Add a shadow effect and border\nbm <- (3 * bml) |>\n  bm_pad(sides = 2L) |>\n  bm_shadow(value = 2L) |>\n  bm_call(cbind) |>\n  bm_extend(sides = 1L, value = 1L)\ncol <- apply(bm + 1L, c(1, 2), function(i) {\n  switch(i, \"white\", \"grey20\", \"lightblue\", \"darkblue\")\n})\ncoords <- xyz_heightmap(bm, col = col, flipy=FALSE)\ngrid.oblicubes(coords, width=unit(2.2, \"mm\"))\n\n\n\n\n\n# Bio 18\nbml <- as_bm_list(\"BIO 18\", font = font)\n\nbm <- (3 * bml) |>\n  bm_pad(sides = 2L) |>\n  bm_shadow(value = 2L) |>\n  bm_call(cbind) |>\n  bm_extend(sides = 1L, value = 1L)\ncol <- apply(bm + 1L, c(1, 2), function(i) {\n  switch(i, \"white\", \"#5b5b5b\", \"#DAA900\", \"#002856\")\n  # switch(i, \"#DAA900\", \"#5b5b5b\", \"#0091b3\", \"#002856\")\n})\ncoords <- xyz_heightmap(bm, col = col, flipy=FALSE)\ngrid.oblicubes(coords, width=unit(2.2, \"mm\"))\n\n\n\n\n\n# Math 32\nbml <- as_bm_list(\"MATH32\", font = font)\n\nbm <- (3 * bml) |>\n  bm_pad(sides = 2L) |>\n  bm_shadow(value = 2L) |>\n  bm_call(cbind) |>\n  bm_extend(sides = 1L, value = 1L)\ncol <- apply(bm + 1L, c(1, 2), function(i) {\n  switch(i, \"white\", \"#5b5b5b\", \"#DAA900\", \"#002856\")\n  # switch(i, \"#DAA900\", \"#5b5b5b\", \"#0091b3\", \"#002856\")\n})\ncoords <- xyz_heightmap(bm, col = col, flipy=FALSE)\ngrid.oblicubes(coords, width=unit(2.2, \"mm\"))\n\n\n\n\n\n# Spark\nbml <- as_bm_list(\"SPORTS\", font = font)\n\nbm <- (3 * bml) |>\n  bm_pad(sides = 2L) |>\n  bm_shadow(value = 2L) |>\n  bm_call(cbind) |>\n  bm_extend(sides = 1L, value = 1L)\ncol <- apply(bm + 1L, c(1, 2), function(i) {\n  switch(i, \"white\", \"#5b5b5b\", \"#DAA900\", \"#002856\")\n  # switch(i, \"#DAA900\", \"#5b5b5b\", \"#0091b3\", \"#002856\")\n})\ncoords <- xyz_heightmap(bm, col = col, flipy=FALSE)\ngrid.oblicubes(coords, width=unit(2.2, \"mm\"))"
  },
  {
    "objectID": "posts/intentional_walks/ibb.html",
    "href": "posts/intentional_walks/ibb.html",
    "title": "Intentional Walks",
    "section": "",
    "text": "Today’s exploration and visualization practive was inspired by this tweet:\n“Barry Bonds has over 200 more intentional walks than the Rays entire franchise.” — Cespedes Family BBQ, Dec. 2, 2013\n“Almost nine years later and Bonds still has 28 more intentional walks than the Rays franchise.” — Jim Passon, Aug. 25, 2022"
  },
  {
    "objectID": "posts/intentional_walks/ibb.html#gathering-the-data",
    "href": "posts/intentional_walks/ibb.html#gathering-the-data",
    "title": "Intentional Walks",
    "section": "Gathering the Data",
    "text": "Gathering the Data\nAt first, I thought that I could reasonably type in all of the data, but Bonds’ career was quite long. I copy-and-pasted the batting table from Baseball Reference and focused on the Year and IBB columns.\nThe franchise page for the Tampa Bay Rays did not have intentional walks quickly accessible, so I simply went through the year-by-year pages and gathered the IBB total (fortunately easy to find visually as the last column).\n\ndf_bonds <- readxl::read_xlsx(\"ibb.xlsx\", sheet = \"Bonds\")\ndf_rays  <- readxl::read_xlsx(\"ibb.xlsx\", sheet = \"Rays\")"
  },
  {
    "objectID": "posts/intentional_walks/ibb.html#data-wrangling",
    "href": "posts/intentional_walks/ibb.html#data-wrangling",
    "title": "Intentional Walks",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nWhile I could probably affect the horizontal axis later in a ggplot visualization, I prefer today to have the data in one data frame. Let me merge the data.\n\ndf <- df_bonds |>\n  full_join(df_rays, by = \"Year\") |>\n  rename(\"IBB_Bonds\" = \"IBB.x\",\n        \"IBB_Rays\" = \"IBB.y\")\n\nThe naturally missing values probably would not affect the calculations much, but for peace of mind, let us impute those values to be zeroes.\n\ndf$IBB_Bonds[is.na(df$IBB_Bonds)] <- 0\ndf$IBB_Rays[is.na(df$IBB_Rays)]   <- 0\n\nIn the spirit of the tweet, we will need to talk about cumulative totals.\n\ndf <- df |>\n  mutate(IBB_Bonds_total = cumsum(IBB_Bonds),\n         IBB_Rays_total  = cumsum(IBB_Rays))"
  },
  {
    "objectID": "posts/intentional_walks/ibb.html#data-visualization",
    "href": "posts/intentional_walks/ibb.html#data-visualization",
    "title": "Intentional Walks",
    "section": "Data Visualization",
    "text": "Data Visualization\nWhile line graphs (with areas filled) would probably be the most visually appealing, it might be better to treat seasons as discrete entries in a bar plot.\n\ndf |>\n  ggplot() +\n  geom_bar(aes(x = Year, y = IBB_Bonds_total),\n           stat = \"identity\")\n\n\n\n\nNow I am curious what the bars will look like in team colors.\n\nbaseplot <- df |>\n  ggplot() +\n  \n  # https://teamcolorcodes.com/san-francisco-giants-color-codes/\n  geom_bar(aes(x = Year, y = IBB_Bonds_total),\n           color = \"#27251F\", fill = \"#FD5A1E\",\n           stat = \"identity\") +\n  \n  # https://teamcolorcodes.com/tampa-bay-rays-color-codes/\n  geom_bar(aes(x = Year, y = IBB_Rays_total),\n           color = \"#8FBCE6\", fill = \"#092C5C\",\n           stat = \"identity\")\n\n# print\nbaseplot\n\n\n\n\nMoving toward aesthetic beauty, I will update some of the theme elements.\n\n# some ideas from\n# https://github.com/nikopech/TidyTuesday/blob/master/R/2022-08-09/2022_08_09_ferris_wheels.R\n\ncurrent_plot <- baseplot +\n  labs(title = \"\",\n       subtitle = \"\",\n       caption = \"Derek Sollberger | August 26, 2022\",\n       x = \"season\",\n       y = \"intentional walk cumulative total\") +\n  theme(legend.position = \"none\",\n        panel.background = element_blank(),\n        plot.background = element_rect(\n            fill = \"#FFFFFF\", \n            color = \"#27251F\"\n        ),\n        plot.title = element_markdown(face = \"italic\",\n                                      margin = margin(b = 5),\n                                      size = 14),\n        plot.title.position = \"plot\",\n        plot.subtitle = element_markdown(face = \"italic\",\n                                         margin = margin(b = 5),\n                                         size = 12),\n        plot.caption = element_markdown(margin = margin(t = 0), \n                                        size = 10),\n        plot.caption.position = \"plot\",\n        plot.margin = margin(50, 50, 50, 50))\n\n# print\ncurrent_plot\n\n\n\n\nNow, I am going to attempt to add arrows (and later: labels) to highlight certain areas of the graph. This is still very new to me, so fingers crossed.\n\ncurrent_plot +\n  # In 2004, Barry Bonds received 120 intentional walks\n  annotate(color = \"#FD5A1E\",\n           geom = \"curve\",\n           size = 0.5,\n           x = 1999, xend = 2004,\n           y = 800, yend = 604) +\n  geom_textbox(aes(x = 1999, y = 800,\n                   color = \"#000000\",\n                   label = \"In 2004, Barry Bonds received 120 intentional walks\"),\n               size = 2) +\n  \n  # Start of Barry Bonds' MLB career\n  annotate(color = \"#FD5A1E\",\n           geom = \"curve\",\n           size = 0.5,\n           x = 1988, xend = 1986,\n           y = 200, yend = 0) +\n  geom_textbox(aes(x = 1988, y = 200,\n                   color = \"#000000\",\n                   label = \"Start of Barry Bonds' MLB career\"),\n               size = 2)\n\n\n\n# print\n# current_plot\n\nAt the moment, I am having difficulty getting labels to naturally appear beyond the panel.\nInstead, I will focus on the title and caption.\n\n# some ideas from\n# https://github.com/nikopech/TidyTuesday/blob/master/R/2022-08-09/2022_08_09_ferris_wheels.R\n\ncurrent_plot <- baseplot +\n  labs(title = \"From 1986 to 2007, Barry Bonds accumulated 688 intentional walks\",\n       subtitle = \"From 1998 to present, the Tampa Bay Rays have accumulated 28 fewer walks\",\n       caption = \"Derek Sollberger | August 26, 2022\",\n       x = \"season\",\n       y = \"intentional walk cumulative total\") +\n  theme(legend.position = \"none\",\n        panel.background = element_blank(),\n        plot.background = element_rect(\n            fill = \"#FFFFFF\", \n            color = \"#27251F\"\n        ),\n        plot.title = element_text(color = \"#FD5A1E\", size = 14, hjust = 0.5),\n        plot.title.position = \"plot\",\n        plot.subtitle = element_text(color = \"#092C5C\", size = 12, hjust = 0.5),\n        plot.caption = element_markdown(margin = margin(t = 0), \n                                        size = 10),\n        plot.caption.position = \"plot\",\n        plot.margin = margin(20, 20, 20, 20))\n\n# print\ncurrent_plot"
  },
  {
    "objectID": "posts/coefficient_of_variation.html",
    "href": "posts/coefficient_of_variation.html",
    "title": "Coefficient of Variation",
    "section": "",
    "text": "For a future lecture in my Sports Analytics course, I want an example of a baseball statistic where the averages for two players are similar, but their variances in that same statistic are quite different. It is still early in the semester, so I am looking for an easy-to-understand statistic. Therefore, I will explore home runs per season."
  },
  {
    "objectID": "posts/coefficient_of_variation.html#a-walk-through-the-data",
    "href": "posts/coefficient_of_variation.html#a-walk-through-the-data",
    "title": "Coefficient of Variation",
    "section": "A Walk Through the Data",
    "text": "A Walk Through the Data\nThe Lahman database contains a lot of baseball statistics, and today I will focus on the Batting data frame.\n\nlibrary(\"Lahman\")\nlibrary(\"tidyverse\")\n\nFor interest, I will filter the observations to retain the players from the past 18 seasons (since my students are about 18 years old, haha) and player-seasons that included at least 100 at-bats.\n\ndf <- Batting |>\n  filter(yearID >= (2021 - 18)) |>\n  filter(AB >= 100)\n\nTo be illustrative, permit me to select mainly the seasons and home run columns.\n\ndf <- df |>\n  select(playerID, yearID, AB, HR)\n\nAt the moment, here is what our data looks like.\n\nhead(df)\n\n   playerID yearID  AB HR\n1 abreubo01   2003 577 20\n2 alfoned01   2003 514 13\n3 almoner01   2003 100  1\n4 alomaro01   2003 263  2\n5 alomaro01   2003 253  3\n6 alomasa02   2003 194  5\n\n\nSince I am concerned with season averages, I am going to group_by the player name. From there, let us then compute the averages and standard deviations for home runs.\n\ndf <- df |>\n  group_by(playerID) |>\n  mutate(xbar = mean(HR, na.rm = TRUE),\n         s    = sd(HR, na.rm = TRUE)) |>\n  ungroup()\nhead(df)\n\n# A tibble: 6 × 6\n  playerID  yearID    AB    HR  xbar      s\n  <chr>      <int> <int> <int> <dbl>  <dbl>\n1 abreubo01   2003   577    20 14.3   8.94 \n2 alfoned01   2003   514    13  8.67  5.86 \n3 almoner01   2003   100     1  1    NA    \n4 alomaro01   2003   263     2  2.67  0.577\n5 alomaro01   2003   253     3  2.67  0.577\n6 alomasa02   2003   194     5  2.33  2.52 \n\n\nFor various reasons, some players only appear once in this subset of data, so their variance is effectively zero (missing in the computation). To answer my original inquiry mathematically, I will now compute the coefficient of variation (and avoid a divide-by-zero error from those players who hit zero home runs).\n\\[CoV = \\frac{s}{\\bar{x}}\\]\n\ndf <- df |>\n  # filter(!is.na(s)) |>\n  filter(xbar > 0) |>\n  mutate(CoV = s/xbar) |>\n  arrange(desc(CoV))\n\nIn this metric, the top scores are\n\nhead(df)\n\n# A tibble: 6 × 7\n  playerID  yearID    AB    HR  xbar     s   CoV\n  <chr>      <int> <int> <int> <dbl> <dbl> <dbl>\n1 gathrjo01   2005   203     0  0.2  0.447  2.24\n2 gathrjo01   2006   154     0  0.2  0.447  2.24\n3 gathrjo01   2006   229     1  0.2  0.447  2.24\n4 gathrjo01   2007   228     0  0.2  0.447  2.24\n5 gathrjo01   2008   279     0  0.2  0.447  2.24\n6 burriem01   2008   240     1  0.25 0.5    2   \n\n\nand the bottom scores are\n\ntail(df)\n\n# A tibble: 6 × 7\n  playerID  yearID    AB    HR  xbar     s   CoV\n  <chr>      <int> <int> <int> <dbl> <dbl> <dbl>\n1 wadela01    2021   336    18    18    NA    NA\n2 wallsta01   2021   152     1     1    NA    NA\n3 walshja01   2021   530    29    29    NA    NA\n4 whiteel04   2021   198     6     6    NA    NA\n5 williju02   2021   119     4     4    NA    NA\n6 wisdopa01   2021   338    28    28    NA    NA"
  },
  {
    "objectID": "posts/coefficient_of_variation.html#heavy-hitters",
    "href": "posts/coefficient_of_variation.html#heavy-hitters",
    "title": "Coefficient of Variation",
    "section": "Heavy Hitters",
    "text": "Heavy Hitters\nSo far, these results seem to be fine mathematically, but they might be uninteresting to the casual baseball fan. To further prune down to recognizable players, let me further filter the data down to players with at least 5 of these 100+ at-bat seasons in the past 18 seasons—and had an average of over 10 home runs per season.\n\ndf <- df |>\n  group_by(playerID) |>\n  mutate(seasons = n()) |>\n  ungroup() |>\n  filter(seasons >= 5) |>\n  filter(xbar >= 5) |>\n  arrange(desc(CoV))\n\nNow, the top scores in using the coefficient of variation as my metric are\n\nhead(df)\n\n# A tibble: 6 × 8\n  playerID  yearID    AB    HR  xbar     s   CoV seasons\n  <chr>      <int> <int> <int> <dbl> <dbl> <dbl>   <int>\n1 santada01   2014   405     7   7.5  10.3  1.38       6\n2 santada01   2015   261     0   7.5  10.3  1.38       6\n3 santada01   2016   233     2   7.5  10.3  1.38       6\n4 santada01   2017   143     3   7.5  10.3  1.38       6\n5 santada01   2019   474    28   7.5  10.3  1.38       6\n6 santada01   2021   116     5   7.5  10.3  1.38       6\n\n\nand the lowest \\(Cov\\) are\n\ntail(df)\n\n# A tibble: 6 × 8\n  playerID  yearID    AB    HR  xbar     s   CoV seasons\n  <chr>      <int> <int> <int> <dbl> <dbl> <dbl>   <int>\n1 delgaca01   2003   570    42  34.5  6.32 0.183       6\n2 delgaca01   2004   458    32  34.5  6.32 0.183       6\n3 delgaca01   2005   521    33  34.5  6.32 0.183       6\n4 delgaca01   2006   524    38  34.5  6.32 0.183       6\n5 delgaca01   2007   538    24  34.5  6.32 0.183       6\n6 delgaca01   2008   598    38  34.5  6.32 0.183       6\n\n\nWell, I do recognize more of the player names, but I realize that the \\(Cov\\) alone does not completely solve my question since I still wanted similar averages between two players."
  },
  {
    "objectID": "posts/coefficient_of_variation.html#a-metric-on-top-of-a-metric",
    "href": "posts/coefficient_of_variation.html#a-metric-on-top-of-a-metric",
    "title": "Coefficient of Variation",
    "section": "A Metric on top of a Metric",
    "text": "A Metric on top of a Metric\nNow, hear me out. If there are two players \\(A\\) and \\(B\\), then what I am looking for is a rate of change of the form\n\\[Y = \\frac{\\text{CoV}_{A} - \\text{CoV}_{B}}{\\bar{x}_{A} - \\bar{x}_{B}}\\]"
  },
  {
    "objectID": "posts/cofficient_of_variation/coefficient_of_variation.html",
    "href": "posts/cofficient_of_variation/coefficient_of_variation.html",
    "title": "Coefficient of Variation",
    "section": "",
    "text": "For a future lecture in my Sports Analytics course, I want an example of a baseball statistic where the averages for two players are similar, but their variances in that same statistic are quite different. It is still early in the semester, so I am looking for an easy-to-understand statistic. Therefore, I will explore home runs per season."
  },
  {
    "objectID": "posts/cofficient_of_variation/coefficient_of_variation.html#a-walk-through-the-data",
    "href": "posts/cofficient_of_variation/coefficient_of_variation.html#a-walk-through-the-data",
    "title": "Coefficient of Variation",
    "section": "A Walk Through the Data",
    "text": "A Walk Through the Data\nThe Lahman database contains a lot of baseball statistics, and today I will focus on the Batting data frame.\n\nlibrary(\"Lahman\")\nlibrary(\"tidyverse\")\n\nFor interest, I will filter the observations to retain the players from the past 18 seasons (since my students are about 18 years old, haha) and player-seasons that included at least 100 at-bats.\n\ndf <- Batting |>\n  filter(yearID >= (2021 - 18)) |>\n  filter(AB >= 100)\n\nTo be illustrative, permit me to select mainly the seasons and home run columns.\n\ndf <- df |>\n  select(playerID, yearID, AB, HR)\n\nAt the moment, here is what our data looks like.\n\nhead(df)\n\n   playerID yearID  AB HR\n1 abreubo01   2003 577 20\n2 alfoned01   2003 514 13\n3 almoner01   2003 100  1\n4 alomaro01   2003 263  2\n5 alomaro01   2003 253  3\n6 alomasa02   2003 194  5\n\n\nSince I am concerned with season averages, I am going to group_by the player name. From there, let us then compute the averages and standard deviations for home runs.\n\ndf <- df |>\n  group_by(playerID) |>\n  mutate(xbar = mean(HR, na.rm = TRUE),\n         s    = sd(HR, na.rm = TRUE)) |>\n  ungroup()\nhead(df)\n\n# A tibble: 6 × 6\n  playerID  yearID    AB    HR  xbar      s\n  <chr>      <int> <int> <int> <dbl>  <dbl>\n1 abreubo01   2003   577    20 14.3   8.94 \n2 alfoned01   2003   514    13  8.67  5.86 \n3 almoner01   2003   100     1  1    NA    \n4 alomaro01   2003   263     2  2.67  0.577\n5 alomaro01   2003   253     3  2.67  0.577\n6 alomasa02   2003   194     5  2.33  2.52 \n\n\nFor various reasons, some players only appear once in this subset of data, so their variance is effectively zero (missing in the computation). To answer my original inquiry mathematically, I will now compute the coefficient of variation (and avoid a divide-by-zero error from those players who hit zero home runs).\n\\[CoV = \\frac{s}{\\bar{x}}\\]\n\ndf <- df |>\n  # filter(!is.na(s)) |>\n  filter(xbar > 0) |>\n  mutate(CoV = s/xbar) |>\n  arrange(desc(CoV))\n\nIn this metric, the top scores are\n\nhead(df)\n\n# A tibble: 6 × 7\n  playerID  yearID    AB    HR  xbar     s   CoV\n  <chr>      <int> <int> <int> <dbl> <dbl> <dbl>\n1 gathrjo01   2005   203     0  0.2  0.447  2.24\n2 gathrjo01   2006   154     0  0.2  0.447  2.24\n3 gathrjo01   2006   229     1  0.2  0.447  2.24\n4 gathrjo01   2007   228     0  0.2  0.447  2.24\n5 gathrjo01   2008   279     0  0.2  0.447  2.24\n6 burriem01   2008   240     1  0.25 0.5    2   \n\n\nand the bottom scores are\n\ntail(df)\n\n# A tibble: 6 × 7\n  playerID  yearID    AB    HR  xbar     s   CoV\n  <chr>      <int> <int> <int> <dbl> <dbl> <dbl>\n1 wadela01    2021   336    18    18    NA    NA\n2 wallsta01   2021   152     1     1    NA    NA\n3 walshja01   2021   530    29    29    NA    NA\n4 whiteel04   2021   198     6     6    NA    NA\n5 williju02   2021   119     4     4    NA    NA\n6 wisdopa01   2021   338    28    28    NA    NA"
  },
  {
    "objectID": "posts/cofficient_of_variation/coefficient_of_variation.html#heavy-hitters",
    "href": "posts/cofficient_of_variation/coefficient_of_variation.html#heavy-hitters",
    "title": "Coefficient of Variation",
    "section": "Heavy Hitters",
    "text": "Heavy Hitters\nSo far, these results seem to be fine mathematically, but they might be uninteresting to the casual baseball fan. To further prune down to recognizable players, let me further filter the data down to players with at least 5 of these 100+ at-bat seasons in the past 18 seasons—and had an average of over 10 home runs per season.\n\ndf <- df |>\n  group_by(playerID) |>\n  mutate(seasons = n()) |>\n  ungroup() |>\n  filter(seasons >= 5) |>\n  filter(xbar >= 15) |>\n  arrange(desc(CoV))\n\nNow, the top scores in using the coefficient of variation as my metric are\n\nhead(df)\n\n# A tibble: 6 × 8\n  playerID  yearID    AB    HR  xbar     s   CoV seasons\n  <chr>      <int> <int> <int> <dbl> <dbl> <dbl>   <int>\n1 solerjo01   2015   366    10  16.3  14.2 0.869       7\n2 solerjo01   2016   227    12  16.3  14.2 0.869       7\n3 solerjo01   2018   223     9  16.3  14.2 0.869       7\n4 solerjo01   2019   589    48  16.3  14.2 0.869       7\n5 solerjo01   2020   149     8  16.3  14.2 0.869       7\n6 solerjo01   2021   308    13  16.3  14.2 0.869       7\n\n\nand the lowest \\(Cov\\) are\n\ntail(df)\n\n# A tibble: 6 × 8\n  playerID  yearID    AB    HR  xbar     s   CoV seasons\n  <chr>      <int> <int> <int> <dbl> <dbl> <dbl>   <int>\n1 delgaca01   2003   570    42  34.5  6.32 0.183       6\n2 delgaca01   2004   458    32  34.5  6.32 0.183       6\n3 delgaca01   2005   521    33  34.5  6.32 0.183       6\n4 delgaca01   2006   524    38  34.5  6.32 0.183       6\n5 delgaca01   2007   538    24  34.5  6.32 0.183       6\n6 delgaca01   2008   598    38  34.5  6.32 0.183       6\n\n\nWell, I do recognize more of the player names, but I realize that the \\(Cov\\) alone does not completely solve my question since I still wanted similar averages between two players."
  },
  {
    "objectID": "posts/cofficient_of_variation/coefficient_of_variation.html#a-metric-on-top-of-a-metric",
    "href": "posts/cofficient_of_variation/coefficient_of_variation.html#a-metric-on-top-of-a-metric",
    "title": "Coefficient of Variation",
    "section": "A Metric on top of a Metric",
    "text": "A Metric on top of a Metric\nNow, hear me out. If there are two players \\(A\\) and \\(B\\), then what I am looking for is a rate of change of the form\n\\[Y = \\bigg|\\frac{s_{A} - s_{B}}{\\bar{x}_{A} - \\bar{x}_{B}}\\bigg|\\]\nFirst, let me simplify the data frame down to just the player names, home run averages, and their standard deviations.\n\ndf2 <- df |>\n  select(playerID, xbar, s) |>\n  distinct()\nhead(df2)\n\n# A tibble: 6 × 3\n  playerID   xbar     s\n  <chr>     <dbl> <dbl>\n1 solerjo01  16.3  14.2\n2 valenjo03  16.2  13.3\n3 muncyma01  20.5  16.6\n4 yelicch01  17.8  13.8\n5 moralke01  16.1  11.7\n6 carpema01  15.5  11.1\n\n\nPresently, I have about 221 observations, so a pair-wise calculations would be computed over about 4.8841^{4} pairs (hopefully manageable by a computer).\n\nN <- nrow(df2)\ndf3 <- data.frame(player1 = rep(NA, N^2),\n                  player2 = rep(NA, N^2),\n                  Y       = rep(NA, N^2))\n\nfor(i in 1:N){\n  for(j in 1:N){\n    row_number = j*(i-1) + j\n    df3$player1[row_number] <- df2$playerID[i]\n    df3$player2[row_number] <- df2$playerID[j]\n    \n    if(i == j){\n      this_Y_value <- 0\n    } else {\n      denominator <- df2$xbar[i] - df2$xbar[j]\n      if(denominator == 0){ denominator <- 0.1 }\n      \n      this_Y_value <- abs((df2$s[i] - df2$s[j]) / denominator)\n    }\n    \n    df3$Y[row_number] <- this_Y_value\n  }\n  \n  # if((row_number %% 10000) == 0){\n  #   print(paste(\"Currently computing row number\", row_number))\n  # }\n}\n\nIn this improvised metric, the top 10 scores were\n\ndf3 |>\n  arrange(desc(Y)) |>\n  top_n(10)\n\nSelecting by Y\n\n\n     player1   player2        Y\n1  mccutan01 ramirjo01 692.3109\n2  polloaj01 utleych01 348.8826\n3  mccutan01 ensbemo01 291.9631\n4  hosmeer01 quentca01 244.8742\n5  mccanbr01  belljo02 209.0920\n6  jacobmi02   bayja01 198.8301\n7   kentje01 giambja01 190.9222\n8  jonesga02 kinslia01 182.2589\n9  contrwi01  shawtr01 180.9609\n10 polloaj01 morrilo01 179.5927\n\n\nUsing the playerInfo() helper function in the Lahman package, we can verify the names of the players.\n\nplayerInfo(\"mccutan01\")\n\n       playerID nameFirst  nameLast\n11832 mccutan01    Andrew McCutchen\n\nplayerInfo(\"ramirjo01\")\n\n       playerID nameFirst nameLast\n14966 ramirjo01      Jose  Ramirez"
  },
  {
    "objectID": "posts/cofficient_of_variation/coefficient_of_variation.html#data-visualization",
    "href": "posts/cofficient_of_variation/coefficient_of_variation.html#data-visualization",
    "title": "Coefficient of Variation",
    "section": "Data Visualization",
    "text": "Data Visualization\nThis whole time, I was hoping for a neat boxplot.\n\ndf |>\n  filter(playerID == \"mccutan01\" | playerID == \"ramirjo01\") |>\n  ggplot(aes(x = playerID, y = HR)) +\n  geom_boxplot(color = c(\"#27251F\", \"#00385D\"),\n               fill = c(\"#FDB827\", \"#E50022\")) +\n  stat_summary(fun=mean, geom=\"point\", shape=20, size=14, color=\"blue\", fill=\"blue\") +\n  scale_x_discrete(labels = c(\"Andrew McCutchen\", \"Jose Ramirez\")) +\n  labs(title = \"Similar Means, Different Variances\",\n       subtitle = stringr::str_wrap(\"Andrew McCutchen and Jose Ramirez have averaged about 20.4 home runs per season, but in different ways (Qualifiers: after 2002 season, 100+ AB seasons, at least 5 100+ AB seasons, home run average over 15 HR/season)\"),\n       caption = \"Derek Sollberger, 2022-09-02\",\n       x = \"MLB Player\",\n       y = \"home runs in a season\") +\n  theme(axis.text.x = element_text(size = 15),\n        legend.position = \"none\",\n        panel.background = element_blank(),\n        plot.background = element_rect(\n            fill = \"#FFFFFF\", \n            color = \"#27251F\"\n        ),\n        plot.title = element_text(color = \"#E50022\", size = 20, hjust = 0.5),\n        plot.title.position = \"plot\",\n        plot.subtitle = element_text(color = \"blue\", size = 12, hjust = 0.0),\n        plot.caption = element_text(color = \"#092C5C\", size = 10, hjust = 1.0),\n        plot.caption.position = \"plot\",\n        plot.margin = margin(20, 20, 20, 20))"
  },
  {
    "objectID": "posts/Settlement_Survival/Settlement_Survival.html",
    "href": "posts/Settlement_Survival/Settlement_Survival.html",
    "title": "Settlement Survival Start",
    "section": "",
    "text": "library(\"DiagrammeR\")\n\nI am going to take some liberties and actually add more prerequisites in the beginning (otherwise, the graph simply starts with about 12 unlinked nodes).\n\nmy_plot <- DiagrammeR::mermaid(\"\n  graph TD\n  start[Select Location]\n  \n  house1[1 House]\n  farms[2 Standard Fields]\n  water[Big Well]\n  forest_hut[Forester's Hut]\n  gather_hut[Gatherer's Hut]\n  hunter_hut[Hunter's Hut]\n  chopping_house[Chopping House]\n  house7[7 Houses]\n  repair_shop[Repair Shop]\n  church[Church]\n  clinic[Clinic]\n  distillery[Distillery]\n  \n  start --> house1\n  start --> farms\n  start --> water\n  start --> gather_hut\n  \n  house1 --> house7\n  farms --> clinic\n  gather_hut --> forest_hut\n  gather_hut --> hunter_hut\n  water --> repair_shop\n  \n  forest_hut --> chopping_house\n  \n  house7 --> church\n  repair_shop --> distillery\n\")\n\n\n# print\nmy_plot"
  },
  {
    "objectID": "posts/patchwork/patchwork.html",
    "href": "posts/patchwork/patchwork.html",
    "title": "Patchwork",
    "section": "",
    "text": "library(\"patchwork\")\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\ncorrelatedValues = function(x, r = 0.9){\n  r2 = r**2\n  ve = 1-r2\n  SD = sqrt(ve)\n  e  = rnorm(length(x), mean=0, sd=SD)\n  y  = r*x + e\n  return(y)\n}\n\nEarlier tonight, I was making these plots for a quick lecture about correlation, so let me just grab some copies.\n\nx <- rnorm(100, mean = 0, sd = 1)\ny <- correlatedValues(x, r = -0.9)\n\ncor_value <- cor(x,y, use = \"pairwise.complete.obs\")\n\ndf_for_graph <- data.frame(x,y)\np1 <- df_for_graph |>\n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  labs(title = \"Correlation Example\",\n       subtitle = paste0(\"r = \", round(cor_value, 4), \n                         \", strongly and negatively correlated\"),\n       caption = \"Spark 01\")\n\n\nx <- rnorm(100, mean = 0, sd = 1)\ny <- correlatedValues(x, r = -0.5)\n\ncor_value <- cor(x,y, use = \"pairwise.complete.obs\")\n\ndf_for_graph <- data.frame(x,y)\np2 <- df_for_graph |>\n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  labs(title = \"Correlation Example\",\n       subtitle = paste0(\"r = \", round(cor_value, 4), \n                         \", slightly and negatively correlated\"),\n       caption = \"Spark 01\")\n\n\nx <- rnorm(100, mean = 0, sd = 1)\ny <- correlatedValues(x, r = 0)\n\ncor_value <- cor(x,y, use = \"pairwise.complete.obs\")\n\ndf_for_graph <- data.frame(x,y)\np3 <- df_for_graph |>\n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  labs(title = \"Correlation Example\",\n       subtitle = paste0(\"r = \", round(cor_value, 4), \n                         \", virtually uncorrelated\"),\n       caption = \"Spark 01\")\n\n\nx <- rnorm(100, mean = 0, sd = 1)\ny <- correlatedValues(x, r = 0.5)\n\ncor_value <- cor(x,y, use = \"pairwise.complete.obs\")\n\ndf_for_graph <- data.frame(x,y)\np4 <- df_for_graph |>\n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  labs(title = \"Correlation Example\",\n       subtitle = paste0(\"r = \", round(cor_value, 4), \n                         \", slightly and positively correlated\"),\n       caption = \"Spark 01\")\n\n\nx <- rnorm(100, mean = 0, sd = 1)\ny <- correlatedValues(x, r = 0.9)\n\ncor_value <- cor(x,y, use = \"pairwise.complete.obs\")\n\ndf_for_graph <- data.frame(x,y)\np5 <- df_for_graph |>\n  ggplot(aes(x = x, y = y)) +\n  geom_point() +\n  labs(title = \"Correlation Example\",\n       subtitle = paste0(\"r = \", round(cor_value, 4), \n                         \", strongly and positively correlated\"),\n       caption = \"Spark 01\")\n\nNow for the patchwork\n\n#patchwork\n(p1 + p2 + p3) / (p4 + p5)\n\n\n\n\nNow for the annotation.\n\noverall_plot <- (p1 + p2 + p3) / (p4 + p5)\n\noverall_plot + plot_annotation(\n  title = \"Overall Title\",\n  subtitle = \"overall subtitle\",\n  caption = \"overall caption\"\n)\n\n\n\n\nGreat! Everything is working as planned."
  },
  {
    "objectID": "posts/wonderwall/wonderwall.html",
    "href": "posts/wonderwall/wonderwall.html",
    "title": "Anyway Heres Wonderwall",
    "section": "",
    "text": "library(\"patchwork\")\nlibrary(\"tidyverse\")"
  },
  {
    "objectID": "posts/wonderwall/wonderwall.html#frets",
    "href": "posts/wonderwall/wonderwall.html#frets",
    "title": "Anyway Heres Wonderwall",
    "section": "Frets",
    "text": "Frets\nI think I will start with the frets. (Disclaimer: I am very much just a beginner with playing guitar, and my descriptions may also be elementary.) I need to represent about 5 rows of space along with 6 columns of strings.\n\ndf <- data.frame(x = 1:6, y = 0:5) #generic data\n\ndf |>\n  ggplot(aes(x = x, y = y))\n\n\n\n\nGuitar chord diagrams are not necessarily scaled with equally spaced units in the horizontal and vertical directions, but that might make things easier for me in this recreational side project. Also, I will apply theme_linedraw temporarily to show what I am thinking.\n\ndf |>\n  ggplot(aes(x = x, y = y)) +\n  coord_equal() +\n  theme_linedraw()\n\n\n\n\nThe \\(y\\) axis has the math-class default, but guitar notation goes in the other direction.\n\n# https://stackoverflow.com/questions/70193132/how-to-reverse-y-axis-values-ggplot2-r\ndf |>\n  ggplot(aes(x = x, y = y)) +\n  coord_equal() +\n  scale_y_reverse() +\n  theme_linedraw()\n\n\n\n\nWhen I remove theme_linedraw (analogy: removing the training wheels from a bicycle), I will need to (at least)\n\nturn off the background color\nturn off the grid line colors\nturn off the border lines too\n\n\ndf |>\n  ggplot(aes(x = x, y = y)) +\n  coord_equal() +\n  scale_y_reverse() +\n  theme(\n    panel.background = element_blank()\n  )\n\n\n\n\nActually, let’s go ahead and give the background a “wood” color.\n\n# https://redketchup.io/color-picker\ndf |>\n  ggplot(aes(x = x, y = y)) +\n  coord_equal() +\n  scale_y_reverse() +\n  theme(\n    panel.background = element_rect(fill = \"#2D2C32\"),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\nLet’s see if we can cutoff the plot at the top (“nut”) and right side of the plot.\n\ndf |>\n  ggplot(aes(x = x, y = y)) +\n  coord_equal() +\n  scale_y_reverse() +\n  theme(\n    panel.background = element_rect(fill = \"#2D2C32\"),\n    panel.grid.minor = element_blank()\n  ) +\n  xlim(c(1,6)) +\n  ylim(c(0,5))\n\nScale for 'y' is already present. Adding another scale for 'y', which will\nreplace the existing scale.\n\n\n\n\n\nThat did not work (and produced a warning because I affected the \\(y\\) axis twice), so perhaps a better strategy is to make a colorful rectangle manually.\n\ndf |>\n  ggplot(aes(x = x, y = y)) +\n  coord_equal() +\n  geom_rect(aes(xmin = 1, xmax = 6, ymin = 0, ymax = 5),\n            fill = \"#2D2C32\") +\n  scale_y_reverse() +\n  theme(\n    panel.background = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\nThis whole time, I have been thinking about making line segments of certain colors for the frets, strings, and the nut. (Note: silver is not a base color in R??)\n\ndf_frets <- data.frame(x1 = 1, x2 = 6, y = 1:5)\ndf_strings <- data.frame(x = 1:6, y1 = 0, y2 = 5)\n\ndf |>\n  ggplot(aes(x = x, y = y)) +\n  coord_equal() +\n  geom_rect(aes(xmin = 1, xmax = 6, ymin = 0, ymax = 5),\n            fill = \"#2D2C32\") +\n  geom_segment(aes(x = x1, y = y, xend = x2, yend = y),\n            color = \"gray50\", data = df_frets) +\n  geom_segment(aes(x = 1, y = 0, xend = 6, yend = 0),\n               color = \"tan\", size = 3) +\n  geom_segment(aes(x = x, y = y1, xend = x, yend = y2),\n            color = \"#C0C0C0\", data = df_strings, size = 2) +\n  scale_y_reverse() +\n  theme(\n    panel.background = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\nThis looks great in my opinion. Let’s turn off the axis tick marks and labels, and save this as a base plot.\n\nfret_background <- df |>\n  ggplot(aes(x = x, y = y)) +\n  coord_equal() +\n  geom_rect(aes(xmin = 1, xmax = 6, ymin = 0, ymax = 5),\n            fill = \"#2D2C32\") +\n  geom_segment(aes(x = x1, y = y, xend = x2, yend = y),\n            color = \"gray50\", data = df_frets) +\n  geom_segment(aes(x = 1, y = 0, xend = 6, yend = 0),\n               color = \"tan\", size = 3) +\n  geom_segment(aes(x = x, y = y1, xend = x, yend = y2),\n            color = \"#C0C0C0\", data = df_strings, size = 2) +\n  scale_y_reverse() +\n  theme(\n    axis.title = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text = element_blank(),\n    panel.background = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n# print\nfret_background"
  },
  {
    "objectID": "posts/wonderwall/wonderwall.html#first-chord-em",
    "href": "posts/wonderwall/wonderwall.html#first-chord-em",
    "title": "Anyway Heres Wonderwall",
    "section": "First Chord (Em)",
    "text": "First Chord (Em)\nAt first, I was thinking of using geom_label to indicate the finger positions, but I bet that using geom_point and then geom_text has more customization options.\n\ndf_em <- data.frame(x = c(2,3), y = c(2,2) - 0.5, label = c(\"1\", \"2\"))\nfret_background +\n  geom_point(aes(x = x, y = y),\n             color = \"blue4\", data = df_em, size = 15) +\n  geom_text(aes(x = x, y = y, label = label),\n             color = \"tan\", data = df_em, size = 10)\n\n\n\n\nLet us go ahead and label this chord. Note that I want the dots to appear in between the frets (hence the “-0.5” in the \\(y\\) coordinates).\n\ndf_em <- data.frame(x = c(2,3), y = c(2,2) - 0.5, label = c(\"1\", \"2\"))\n\nchord_em <- fret_background +\n  geom_point(aes(x = x, y = y),\n             color = \"blue4\", data = df_em, size = 12) +\n  geom_text(aes(x = x, y = y, label = label),\n             color = \"tan\", data = df_em, size = 8) +\n  labs(title = \"Em\") +\n  theme(plot.title = element_text(size = 20, face = \"bold\", hjust = 0.5))\n\n# print\nchord_em"
  },
  {
    "objectID": "posts/wonderwall/wonderwall.html#the-other-four-chords",
    "href": "posts/wonderwall/wonderwall.html#the-other-four-chords",
    "title": "Anyway Heres Wonderwall",
    "section": "The Other Four Chords",
    "text": "The Other Four Chords\n\ndf_g <- data.frame(x = c(2,1,6), y = c(2,3,3) - 0.5, label = c(\"1\", \"2\", \"4\"))\n\nchord_g <- fret_background +\n  geom_point(aes(x = x, y = y),\n             color = \"blue4\", data = df_g, size = 12) +\n  geom_text(aes(x = x, y = y, label = label),\n             color = \"tan\", data = df_g, size = 8) +\n  labs(title = \"G\") +\n  theme(plot.title = element_text(size = 20, face = \"bold\", hjust = 0.5))\n\n# print\nchord_g\n\n\n\n\nThis is something that I worried about. In guitar chord diagrams, there are indicators to tell the player if a string is played open (indicated with an “O”, that is that no fingers are placed on the strings while the string is strung) or if a string is closed (not strung at all, indicated with an “X”), but these indicators are placed above the nut—for our purposes: outside of the graph.\n\ndf_d <- data.frame(x = c(4,6,5), y = c(2,2,3) - 0.5, label = c(\"1\", \"2\", \"3\"))\n\nchord_d <- fret_background +\n  geom_point(aes(x = x, y = y),\n             color = \"blue4\", data = df_d, size = 12) +\n  geom_text(aes(x = x, y = y, label = label),\n             color = \"tan\", data = df_d, size = 8) +\n  geom_text(aes(x = 1, y = -0.2, label = \"X\"), size = 5) +\n  geom_text(aes(x = 2, y = -0.2, label = \"X\"), size = 5) +\n  labs(title = \"D\") +\n  theme(plot.title = element_text(size = 20, face = \"bold\", hjust = 0.5))\n\n# print\nchord_d\n\n\n\n\n\ndf_a7sus4 <- data.frame(x = c(3,5), y = c(2,3) - 0.5, label = c(\"1\", \"2\"))\n\nchord_a7sus4 <- fret_background +\n  geom_point(aes(x = x, y = y),\n             color = \"blue4\", data = df_a7sus4, size = 12) +\n  geom_text(aes(x = x, y = y, label = label),\n             color = \"tan\", data = df_a7sus4, size = 8) +\n  geom_text(aes(x = 1, y = -0.2, label = \"X\"), size = 5) +\n  labs(title = \"A7sus4\") +\n  theme(plot.title = element_text(size = 20, face = \"bold\", hjust = 0.5))\n\n# print\nchord_a7sus4\n\n\n\n\n\ndf_c <- data.frame(x = c(5,3,2), y = c(1,2,3) - 0.5, label = c(\"1\", \"2\", \"3\"))\n\nchord_c <- fret_background +\n  geom_point(aes(x = x, y = y),\n             color = \"blue4\", data = df_c, size = 12) +\n  geom_text(aes(x = x, y = y, label = label),\n             color = \"tan\", data = df_c, size = 8) +\n  geom_text(aes(x = 1, y = -0.2, label = \"X\"), size = 5) +\n  labs(title = \"C\") +\n  theme(plot.title = element_text(size = 20, face = \"bold\", hjust = 0.5))\n\n# print\nchord_c"
  },
  {
    "objectID": "posts/wonderwall/wonderwall.html#first-draft",
    "href": "posts/wonderwall/wonderwall.html#first-draft",
    "title": "Anyway Heres Wonderwall",
    "section": "First Draft",
    "text": "First Draft\nWith 5 chords, I am imagining a layout of plots with about 2 rows.\n\n(chord_em + chord_g + chord_d) / (chord_a7sus4 + chord_c)"
  },
  {
    "objectID": "posts/wonderwall/wonderwall.html#a-caption-tile",
    "href": "posts/wonderwall/wonderwall.html#a-caption-tile",
    "title": "Anyway Heres Wonderwall",
    "section": "A Caption Tile",
    "text": "A Caption Tile\nYes, I figured that I would want to squeeze in a “square” of text somewhere to even out the image.\n\n# https://statisticsglobe.com/plot-only-text-in-r\ncaption_plot <- ggplot() +\n  annotate(\"text\",\n           x = 1, y = 1,\n           size = 5,\n           label = \"Wonderwall by Oasis\\n \\nsimplified tab\\nvia Ultimate Guitar\\ncapo: 2nd fret\\nkey: F#m\") +\n  coord_equal() +\n  theme(\n    axis.title = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text = element_blank(),\n    panel.background = element_rect(fill = \"#2D2C32\"),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank()\n  )\n\n# print\ncaption_plot\n\n\n\n\nNow to see if this “caption plot” fits in nicely.\n\n(chord_em + chord_g + chord_d) / (chord_a7sus4 + caption_plot +chord_c)\n\n\n\n\nAt the time of this writing, it is near midnight, and my motivation for refinement is decreasing rapidly, lol.\n\nmain_plot <- (chord_em + chord_g + chord_d) / (chord_a7sus4 + caption_plot +chord_c)"
  },
  {
    "objectID": "posts/wonderwall/wonderwall.html#strumming-pattern",
    "href": "posts/wonderwall/wonderwall.html#strumming-pattern",
    "title": "Anyway Heres Wonderwall",
    "section": "Strumming Pattern",
    "text": "Strumming Pattern\nI, and I assume other beginners, do not natually pick up a strumming pattern by ear. Fortunately, the tab did include that. But how do I add the pattern to this diagram?\n\n# https://community.rstudio.com/t/up-and-down-arrows-inside-r/76287\n\n# first, I will type into words, and then do a search-and-replace\n# down, pause, down, pause, down, pause, down, up, down, up, down, pause, down, pause, down, up, down, up, down, pause, down, pause, down, up, pause, up, pause, up, down, pause, down, pause\nstrumming_pattern <- intToUtf8(c(8595, 8196, 8595, 8196, 8595, 8196, 8595, 8593, 8595, 8593, 8595, 8196, 8595, 8196, 8595, 8593, 8595, 8593, 8595, 8196, 8595, 8196, 8595, 8593, 8196, 8593, 8196, 8593, 8595, 8196, 8595, 8196))"
  },
  {
    "objectID": "posts/wonderwall/wonderwall.html#annotationg-and-echoing-the-meme",
    "href": "posts/wonderwall/wonderwall.html#annotationg-and-echoing-the-meme",
    "title": "Anyway Heres Wonderwall",
    "section": "Annotationg and Echoing the Meme",
    "text": "Annotationg and Echoing the Meme\nWith patchwork, we can furthermore add a title, subtitle, and/or caption to the overall plot.\n\nfinal_plot <- main_plot +\n  plot_annotation(title = \"Anyway, Here's Wonderwall\",\n                  caption = paste(\"strumming pattern:\", strumming_pattern, \"\\nGraph by @DerekSollberger\"),\n                  theme = theme(plot.title = element_text(\n                    size = 25, hjust = 0.5\n                  ),\n                  plot.caption = element_text(\n                    size = 20, hjust = 0.5\n                  )))\n\n# print\nfinal_plot\n\n\n\n\n\nggsave(\"wonderwall.png\", plot = final_plot, device = \"png\",\n       width = 8, height = 6, units = \"in\")\n\n\n\n\nmeme chart"
  },
  {
    "objectID": "posts/Canvas_Roster/Canvas_Roster.html",
    "href": "posts/Canvas_Roster/Canvas_Roster.html",
    "title": "Canvas_Roster",
    "section": "",
    "text": "With the goal of learning my students’ names faster, I wrote an R script that will convert a roster (“People” in a Canvas course) to a gt table for later offline use.\n\nknitr::opts_chunk$set(eval = FALSE)\n\n\nSetup\nIn your Canvas course, go to People, right-click on the roster, and click “Save Page As”\n\nbe sure to save the “complete” web page (this creates a folder with all of the students’ pictures)\nplace the also downloaded HTML file into the folder\nplace this code script into the folder\n\n\n# change this file name as needed\nHTML_file_name <- \"Course Roster S23-BIO 018 01.htm\"\n\nlibrary(\"gt\")\nlibrary(\"gtExtras\")\nlibrary(\"rvest\")\nlibrary(\"tidyverse\")\n\n\n\nRoster table\nhttps://www.r-bloggers.com/2020/04/scrape-html-table-using-rvest/\n\ncontent <- read_html(HTML_file_name)\ntables <- content |> html_table(fill = TRUE)\nroster_table <- tables[[1]]\n\nroster_df <- roster_table |>\n  select(Name, Section) |>\n  mutate(discussion_tag = str_extract(Section, \"Discussion-\\\\d\\\\dD\")) |>\n  separate(discussion_tag, sep = \"-\", into = c(\"disregard\", \"discussion_section\")) |>\n  select(Name, discussion_section) |>\n  \n  # remove instructor of record\n  filter(!is.na(discussion_section))\n\n\n\nImages\nhttps://community.rstudio.com/t/scraping-images-from-the-web/133239\n\nimage_urls <- content |> html_elements(\"img\")\nnum_images <- length(image_urls)\n\nimage_df_raw <- data.frame(html_raw = rep(NA, num_images))\nfor(img in 1:num_images){\n  image_df_raw$html_raw[img] <- as.character(image_urls[[img]])\n}\n\nimage_df <- image_df_raw |>\n  \n  # skip first two images?\n  slice(3:n()) |>\n  \n  # roundabout because some people's names have more than 2 words\n  separate(col = \"html_raw\", sep = \"alt=\", \n           into = c(\"part1\", \"part2\")) |>\n  \n  separate(col = \"part1\", sep = \" \", into = c(\"tag1\", \"src\")) |>\n  separate(col = \"src\", sep = \"/\", into = c(\"stem\", \"profile_picture\")) |>\n  separate(col = \"part2\", sep = \" aria\", into = c(\"student_name\", \"tag2\")) |>\n  \n  select(profile_picture, student_name)\n\n# remove quotation marks\nimage_df$profile_picture <- str_replace_all(image_df$profile_picture, \"\\\"\", \"\")\nimage_df$student_name <- str_replace_all(image_df$student_name, \"\\\"\", \"\")\n\n\n\nMerge\n\nroster_df <- roster_df |>\n  left_join(image_df, by = c(\"Name\" = \"student_name\")) |>\n  select(profile_picture, Name, discussion_section)\n\n\n\ngt\nhttps://jthomasmock.github.io/gtExtras/reference/gt_img_rows.html\n\nroster_gt <- roster_df |>\n  gt() |>\n  gt_img_rows(columns = profile_picture, img_source = \"local\")\n\n\ngtsave(roster_gt, \"roster.png\")"
  },
  {
    "objectID": "posts/California_weather/California_weather.html",
    "href": "posts/California_weather/California_weather.html",
    "title": "California Weather",
    "section": "",
    "text": "library(\"tidyverse\")\n\nI want to create and visualize a simple data set for my Data Science courses (that I teach in California).\n\nData Source\n\nUniversity of California\nAgriculture and Natural Resources\nStatewide Integrated Pest Management Program\nhttps://ipm.ucanr.edu/WEATHER/wxactstnames.html\n\n\n\nFixed-Width Files\nToday I learned how to read fixed-width files in the Tidyverse. From there, I simply need to give the columns easy-to-use names.\n\nSF_df <- readr::read_fwf(\"SF_2021.txt\")\n\nRows: 365 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\n\nchr  (3): X1, X4, X7\ndbl  (3): X3, X5, X6\ntime (1): X2\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncolnames(SF_df) <- c(\"date\", \"time\", \"precipitation\",\n                     \"check1\", \"high\", \"low\", \"check2\")"
  },
  {
    "objectID": "posts/Christmas_plots/Christmas_plots.html",
    "href": "posts/Christmas_plots/Christmas_plots.html",
    "title": "Seasons Greetings by Riinu Pius",
    "section": "",
    "text": "a place to collect nerdy holiday plots\n\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n# https://gist.github.com/riinuots/52c0089bd5c41a44389e95cc8cb3943d\none = tibble(x    = c(2, 4, 3, 2.75, 2.75, 3.25, 3.25),\n             y    = c(1, 1, 6, 0,    1,    1,    0),\n            group = c(rep(\"#005a32\", 3), rep(\"#543005\", 4)))\n              \nggplot(one, aes(x, y, fill = group)) +\n  geom_polygon()\n\n\n\n\n\ntwo = tribble(~x,   ~y,\n              2.7,  2,\n              3,    3,\n              3.4,  1.6,\n              3.5,  2.5,\n              3.1,  4,\n              2.95, 5,\n              2.7,  3.7,\n              2.4,  2.45,\n              2.35, 1.7,\n              3.1,  2.1,\n              3.2,  3.1,\n              2.75, 3,\n              2.9, 1.4,\n              2.9, 4.4) %>% \n  mutate(group = \"gold\")\n\nggplot(one, aes(x, y, fill = group)) +\n  geom_polygon() +\n  geom_point(data = two, shape = 21, size = 5)"
  },
  {
    "objectID": "posts/greenhouse/greenhouse.html",
    "href": "posts/greenhouse/greenhouse.html",
    "title": "Stardew Valley Crops",
    "section": "",
    "text": "Here is some quick code to help me plan a crop layout in Stardew Valley.\n\nlibrary(\"figpatch\") #https://bradyajohnston.github.io/figpatch/\nlibrary(\"patchwork\")\n\n\n# load images\n# https://stardewvalleywiki.com/Crops\nancient_fruit <- figpatch::fig(\"Ancient_Fruit.png\")\nblueberry <- figpatch::fig(\"Blueberry.png\")\ncactus_fruit <- figpatch::fig(\"Cactus_Fruit.png\")\ncoffee_bean <- figpatch::fig(\"Coffee_Bean.png\")\ncorn <- figpatch::fig(\"Corn.png\")\ncranberries <- figpatch::fig(\"Cranberries.png\")\ngrape <- figpatch::fig(\"Grape.png\")\ngreen_bean <- figpatch::fig(\"Green_Bean.png\")\nhops <- figpatch::fig(\"Hops.png\")\nhot_pepper <- figpatch::fig(\"Hot_Pepper.png\")\npineapple <- figpatch::fig(\"Pineapple.png\")\nstrawberry <- figpatch::fig(\"Strawberry.png\")\ntea_leaves <- figpatch::fig(\"Tea_Leaves.png\")\ntomato <- figpatch::fig(\"Tomato.png\")\n\n\ngreenhouse_plot <- patchwork::wrap_plots(\n  \n  # row 1\n  grape, hops, hot_pepper, hot_pepper, hot_pepper, hot_pepper, hot_pepper, hot_pepper, hot_pepper, hot_pepper, hot_pepper, hot_pepper,\n  \n  # row 2\n  grape, hops, tomato, tomato, tomato, tomato, tomato, tomato, tomato, tomato, tomato, tomato, \n  \n  # row 3\n  grape, tea_leaves, cranberries, cranberries, cranberries, cranberries, cranberries, cranberries, cranberries, cranberries, cranberries, cranberries, \n  \n  # row 4\n  grape, tea_leaves, strawberry, strawberry, strawberry, strawberry, strawberry, strawberry, strawberry, strawberry, strawberry, strawberry, \n  \n  # row 5\n  grape, tea_leaves, cactus_fruit, cactus_fruit, cactus_fruit, cactus_fruit, cactus_fruit, cactus_fruit, cactus_fruit, cactus_fruit, cactus_fruit, cactus_fruit, \n  \n  # row 6\n  green_bean, tea_leaves, corn, corn, corn, corn, corn, corn, corn, corn, corn, corn, \n  \n  # row 7\n  green_bean, tea_leaves, ancient_fruit, ancient_fruit, ancient_fruit, ancient_fruit, ancient_fruit, ancient_fruit, ancient_fruit, ancient_fruit, ancient_fruit, ancient_fruit, \n  \n  # row 8\n  green_bean, tea_leaves, blueberry, blueberry, blueberry, blueberry, blueberry, blueberry, blueberry, blueberry, blueberry, blueberry, \n  \n  # row 9\n  green_bean, hops, pineapple, pineapple, pineapple, pineapple, pineapple, pineapple, pineapple, pineapple, pineapple, pineapple, \n  \n  # row 10\n  green_bean, hops, coffee_bean, coffee_bean, coffee_bean, coffee_bean, coffee_bean, coffee_bean, coffee_bean, coffee_bean, coffee_bean, coffee_bean, \n  \n  ncol = 12\n)\n\n\ngreenhouse_plot +\n  patchwork::plot_annotation(title = \"Stardew Valley\",\n                  subtitle = \"crops that continue to produce\")"
  },
  {
    "objectID": "posts/curly_operator/curly_operator.html",
    "href": "posts/curly_operator/curly_operator.html",
    "title": "curly operator",
    "section": "",
    "text": "The “curly operator” was added in rlang a few years ago, and I have yet to really use it much. It came in handy during a data analyst consulting gig I had during the summer of 2021, and I should use it more.\n\nlibrary(\"palmerpenguins\")\nlibrary(\"tidyverse\")\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nFor instance, can I make a helper function to reduce typing out the same few lines of code that I use often?\n\nsummary_stats <- function(data_frame, grouping_variable, numerical_variable){\n  data_frame |>\n    filter(!is.na({{grouping_variable}})) |>\n    group_by({{grouping_variable}}) |>\n    summarize(min = min({{numerical_variable}}, na.rm = TRUE),\n            xbar = mean({{numerical_variable}}, na.rm = TRUE),\n            med = median({{numerical_variable}}, na.rm = TRUE),\n            s = sd({{numerical_variable}}, na.rm = TRUE),\n            max = max({{numerical_variable}}, na.rm = TRUE))\n}\n\n\nsummary_stats(penguins, species, bill_length_mm)\n\n# A tibble: 3 × 6\n  species     min  xbar   med     s   max\n  <fct>     <dbl> <dbl> <dbl> <dbl> <dbl>\n1 Adelie     32.1  38.8  38.8  2.66  46  \n2 Chinstrap  40.9  48.8  49.6  3.34  58  \n3 Gentoo     40.9  47.5  47.3  3.08  59.6\n\n\n\nsummary_stats(penguins, island, body_mass_g)\n\n# A tibble: 3 × 6\n  island      min  xbar   med     s   max\n  <fct>     <int> <dbl> <dbl> <dbl> <int>\n1 Biscoe     2850 4716. 4775   783.  6300\n2 Dream      2700 3713. 3688.  417.  4800\n3 Torgersen  2900 3706. 3700   445.  4700"
  },
  {
    "objectID": "posts/JupyterHub_showcase/JupyterHub_showcase.html",
    "href": "posts/JupyterHub_showcase/JupyterHub_showcase.html",
    "title": "JupyterHub Showcase",
    "section": "",
    "text": "library(\"palmerpenguins\")\nlibrary(\"tidyverse\")"
  },
  {
    "objectID": "posts/JupyterHub_showcase/JupyterHub_showcase.html#login",
    "href": "posts/JupyterHub_showcase/JupyterHub_showcase.html#login",
    "title": "JupyterHub Showcase",
    "section": "Login",
    "text": "Login\nAt UC Merced, our 2i2c server is located at\n\nhttps://ucmerced.2i2c.cloud\n\nEach user sees a shared and a shared-readwrite folder\n\n\n\nshared and shared-readwrite"
  },
  {
    "objectID": "posts/JupyterHub_showcase/JupyterHub_showcase.html#file-structure",
    "href": "posts/JupyterHub_showcase/JupyterHub_showcase.html#file-structure",
    "title": "JupyterHub Showcase",
    "section": "File Structure",
    "text": "File Structure\nFor this demonstration, I have made the following directories in the root directory.\n\nExampleCourse_instructor\nExampleCourse_student\n\nalong with an ExampleCourse inside the shared-readwrite directory.\n\n\n\nfile_structure"
  },
  {
    "objectID": "posts/JupyterHub_showcase/JupyterHub_showcase.html#making-an-assignment",
    "href": "posts/JupyterHub_showcase/JupyterHub_showcase.html#making-an-assignment",
    "title": "JupyterHub Showcase",
    "section": "Making an Assignment",
    "text": "Making an Assignment\nThis semester, I taught classes with the R programming language, and here I will continue to use R. I start my work inside of the ExampleCourse-instructor directory. We will create an assignment inside of a Jupyter notebook, but with an R kernel. In other words, click on the “R” button under “Notebook”\nThis script has been named HW1.ipynb.\nThe 2i2c server comes with the Otter Grader tools built by data science faculty at UC Berkeley. Instructors can highly customize the functionality of these files with the initialization cell (a raw code block).\n\n\n\ninitialization\n\n\nMy colleagues and I have discussed ways to ease beginning students into the skills of installing code packages. For the sake of visual brevity, here I will assume that the code packages have been installed already.\n\n# code packages\nlibrary(\"palmerpenguins\")\nlibrary(\"tidyverse\")\n\n\nstr(penguins)\n\n\nPrompts\nInstructions for the student can be made with normal typing augmented by markdown as this notebook environment is built for literate programming.\n\n\n\ninstructions are typed in markdown\n\n\n\n# HW1\n\nIn this assignment, we will build a custom function to compute sample statistics.  Pay attention to the usage of the curly braces `{{...}}`, and we will use the functions on the `palmerpenguins` data set\n\n\n1. Write a custom function called `summary_stats` that takes 3 inputs\n\n    * data_frame\n    * grouping_variable\n    * numerical_variable\n\nand outputs the `summarize` command on the following sample statistics: minimum, mean, median, standard deviation, and maximum.  Please follow the given stencil.\n\n\n\nWriting a Problem\nInside of a code cell, an instructor can type in the intended answer between # BEGIN SOLUTION and # END SOLUTION comments. From there, what the student will see falls between the # BEGIN PROMPT and # END PROMPT comments.\n\n\n\nan example coding task (from the instructors point of view)\n\n\n\n1. Write a custom function called `summary_stats` that takes 3 inputs\n\n    * data_frame\n    * grouping_variable\n    * numerical_variable\n\nand outputs the `summarize` command on the following sample statistics: minimum, mean, median, standard deviation, and maximum.  Please follow the given stencil.\n\n\n# BEGIN SOLUTION NO PROMPT\nsummary_stats <- function(data_frame, grouping_variable, numerical_variable){\n  data_frame |>\n    filter(!is.na({{grouping_variable}})) |>\n    group_by({{grouping_variable}}) |>\n    summarize(min = min({{numerical_variable}}, na.rm = TRUE),\n            xbar = mean({{numerical_variable}}, na.rm = TRUE),\n            med = median({{numerical_variable}}, na.rm = TRUE),\n            s = sd({{numerical_variable}}, na.rm = TRUE),\n            max = max({{numerical_variable}}, na.rm = TRUE))\n}\n# END SOLUTION\n. = \" # BEGIN PROMPT\nsummary_stats <- function(data_frame, grouping_variable, numerical_variable){\n  data_frame |>\n    filter(!is.na({{grouping_variable}})) |>\n    group_by({{grouping_variable}}) |>\n    summarize(min = min({{numerical_variable}}, na.rm = TRUE),\n            xbar = _____,\n            med = _____,\n            s = _____,\n            max = _____)\n}\n\" # END PROMPT\n\n\n2. Use your `summary_stats` function with the `penguins` data frame, grouped by the `species` categorical variable, on the `bill_length_mm` numerical variable.\n\n\n# BEGIN SOLUTION NO PROMPT\nsummary_stats(penguins, species, bill_length_mm)\n# END SOLUTION\n. = \" # BEGIN PROMPT\nsummary_stats(penguins, _____, _____)\n\" # END PROMPT\n\n\n3. Use your `summary_stats` function with the `penguins` data frame, grouped by the `island` categorical variable, on the `body_mass_g` numerical variable.\n\n\n# BEGIN SOLUTION NO PROMPT\nsummary_stats(penguins, island, body_mass_g)\n# END SOLUTION\n. = \" # BEGIN PROMPT\n\n\" # END PROMPT\n\n\n\nTest That\nAdvanced R programmers, especially those that make code packages, use the testthat package to create unit tests to verify that functions are working as intended. The Otter Grader framework continues this idea for making assignments in R.\n\n# If you want to check your code right now, uncomment the following line of code and run it\n# testthat::expect_equal(summary_stats(penguins, island, body_mass_g)$s[1], 782.8557, tol = 0.01)"
  },
  {
    "objectID": "posts/JupyterHub_showcase/JupyterHub_showcase.html#assigning-the-assignment",
    "href": "posts/JupyterHub_showcase/JupyterHub_showcase.html#assigning-the-assignment",
    "title": "JupyterHub Showcase",
    "section": "Assigning the Assignment",
    "text": "Assigning the Assignment\nNow we will show the power of Otter Assign! Inside JupyterHub, open a terminal connection\n\nFile –> New –> Terminal\n\nUse the cd Unix command to navigate to the instructor files.\ncd ExampleCourse_instructor/\nSince our assignment is called HW1.ipynb, we will assign that notebook into the shared-readwrite directory. Tip: it is also a good idea to create a new directory for each homework assignment (to later manage solution files and student submissions).\notter assign HW1.ipynb ../shared-readwrite/ExampleCourse/HW1\n\n\n\nOtter Assign\n\n\nVerify that the HW1 directory was created within shared-readwrite/ExampleCourse."
  },
  {
    "objectID": "posts/JupyterHub_showcase/JupyterHub_showcase.html#student-view",
    "href": "posts/JupyterHub_showcase/JupyterHub_showcase.html#student-view",
    "title": "JupyterHub Showcase",
    "section": "Student View",
    "text": "Student View\nWe also find our HW1 directory inside the shared directory. The shared directory is in a read-only state, so students will not be able to edit and save their work there.\nThe easiest route is for a student to download the HW1.ipynb file and then upload it into their ExampleCourse_student directory. Advanced users can use Unix commands for this copy.\ncp shared/ExampleCourse/HW1/student/HW1.ipynb ExampleCourse_student\nNotice how the student receives only the partial prompts and is ready for some homework!\n\n\n\nstudent view"
  },
  {
    "objectID": "posts/Dartmouth_Atlas_data/Dartmouth_Atlas_data.html",
    "href": "posts/Dartmouth_Atlas_data/Dartmouth_Atlas_data.html",
    "title": "hospital_data",
    "section": "",
    "text": "https://data.dartmouthatlas.org/\n\nlibrary(\"sf\")\n\nLinking to GEOS 3.9.3, GDAL 3.5.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\nlibrary(\"tidyverse\")\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n\n\nmap_data <- sf::read_sf(\"HRR_Bdry__AK_HI_unmodified/hrr-shapefile/Hrr98Bdry_AK_HI_unmodified.shp\")\n\nmap_data |>\n  ggplot() +\n  geom_sf()"
  },
  {
    "objectID": "posts/JupyterHub_showcase/HW1.html",
    "href": "posts/JupyterHub_showcase/HW1.html",
    "title": "The Median Data Scientist",
    "section": "",
    "text": "BEGIN ASSIGNMENT init_cell: false export_cell: true\n\n# code packages\nlibrary(\"palmerpenguins\")\nlibrary(\"tidyverse\")\n\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\n\nHW1\nIn this assignment, we will build a custom function to compute sample statistics. Pay attention to the usage of the curly braces {{...}}, and we will use the functions on the palmerpenguins data set\n\nWrite a custom function called summary_stats that takes 3 inputs\n\ndata_frame\ngrouping_variable\nnumerical_variable\n\n\nand outputs the summarize command on the following sample statistics: minimum, mean, median, standard deviation, and maximum. Please follow the given stencil.\n\n# BEGIN SOLUTION NO PROMPT\nsummary_stats <- function(data_frame, grouping_variable, numerical_variable){\n  data_frame |>\n    filter(!is.na({{grouping_variable}})) |>\n    group_by({{grouping_variable}}) |>\n    summarize(min = min({{numerical_variable}}, na.rm = TRUE),\n            xbar = mean({{numerical_variable}}, na.rm = TRUE),\n            med = median({{numerical_variable}}, na.rm = TRUE),\n            s = sd({{numerical_variable}}, na.rm = TRUE),\n            max = max({{numerical_variable}}, na.rm = TRUE))\n}\n# END SOLUTION\n. = \" # BEGIN PROMPT\nsummary_stats <- function(data_frame, grouping_variable, numerical_variable){\n  data_frame |>\n    filter(!is.na({{grouping_variable}})) |>\n    group_by({{grouping_variable}}) |>\n    summarize(min = min({{numerical_variable}}, na.rm = TRUE),\n            xbar = _____,\n            med = _____,\n            s = _____,\n            max = _____)\n}\n\" # END PROMPT\n\n\nUse your summary_stats function with the penguins data frame, grouped by the species categorical variable, on the bill_length_mm numerical variable.\n\n\n# BEGIN SOLUTION NO PROMPT\nsummary_stats(penguins, species, bill_length_mm)\n# END SOLUTION\n. = \" # BEGIN PROMPT\nsummary_stats(penguins, _____, _____)\n\" # END PROMPT\n\n\n\nA tibble: 3 × 6\n\n    speciesminxbarmedsmax\n    <fct><dbl><dbl><dbl><dbl><dbl>\n\n\n    Adelie   32.138.7913938.802.66340546.0\n    Chinstrap40.948.8338249.553.33925658.0\n    Gentoo   40.947.5048847.303.08185759.6\n\n\n\n\n\nUse your summary_stats function with the penguins data frame, grouped by the island categorical variable, on the body_mass_g numerical variable.\n\n\n# BEGIN SOLUTION NO PROMPT\nsummary_stats(penguins, island, body_mass_g)\n# END SOLUTION\n. = \" # BEGIN PROMPT\n\n\" # END PROMPT\n\n\n\nA tibble: 3 × 6\n\n    islandminxbarmedsmax\n    <fct><int><dbl><dbl><dbl><int>\n\n\n    Biscoe   28504716.0184775.0782.85576300\n    Dream    27003712.9033687.5416.64414800\n    Torgersen29003706.3733700.0445.10794700\n\n\n\n\n\n# If you want to check your code right now, uncomment the following line of code and run it\n# testthat::expect_equal(summary_stats(penguins, island, body_mass_g)$s[1], 782.8557, tol = 0.01)\n\n\n\nSubmission\nOnce you are done with the tasks above,\n\nGo to “File”\nClick “Download as”\nDownload as “Notebook (.ipynb)\n\nThat will download a copy of this notebook onto your computer (probably into your Downloads folder). Please upload the .ipynb file back into our CatCourses site."
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#math-biology-video-project-1",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#math-biology-video-project-1",
    "title": "Math Biology Video Project",
    "section": "Math Biology Video Project",
    "text": "Math Biology Video Project\n\n\n\nEcology course (prereq: Intro Bio)\nFall 2018 semester\n91 students (85 students in study)\n24 videos\n\nabout 10 minutes per video\n\n\n\n\n\n\nimage credit: Shutterstock"
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#learner-profile",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#learner-profile",
    "title": "Math Biology Video Project",
    "section": "Learner Profile",
    "text": "Learner Profile\n\n\n\n\n\nmath background\n\n\n\n\nmostly sophomores\nprior experience in flipped classrooms\nmostly White and Asian students\n77 percent female"
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#literature",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#literature",
    "title": "Math Biology Video Project",
    "section": "Literature",
    "text": "Literature\n\nValuesValues 2EmotionsEmotions 2\n\n\n\n\n\nAndrews 2017\n\n\n\n\n\n\n\nMath Biology Values Instrument\n\n\n\n\n\n\n\nWachsmuth 2017\n\n\n\n\n\n\n\nMath Emotions Instrument"
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#fall-2018-semester",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#fall-2018-semester",
    "title": "Math Biology Video Project",
    "section": "Fall 2018 Semester",
    "text": "Fall 2018 Semester\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur first glance at the survey data showed no significant results between the pre and post surveys."
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#discretize",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#discretize",
    "title": "Math Biology Video Project",
    "section": "Discretize",
    "text": "Discretize\nWe grouped students into “unchanged”, “increase”, or “decrease” groups based on their pre- and post-semester survey results for the MBVI queries—where “unchanged” was a difference of -1, 0, or 1 on the 7-point Likert scales"
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#math-content",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#math-content",
    "title": "Math Biology Video Project",
    "section": "Math Content",
    "text": "Math Content\n\n\n\n\nOne VideoAll Videos"
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#math-emotion",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#math-emotion",
    "title": "Math Biology Video Project",
    "section": "Math Emotion",
    "text": "Math Emotion"
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#mbvi",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#mbvi",
    "title": "Math Biology Video Project",
    "section": "MBVI",
    "text": "MBVI\nMath Biology Values Instrument"
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#video-stats",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#video-stats",
    "title": "Math Biology Video Project",
    "section": "Video Stats",
    "text": "Video Stats\n\nPlaysVisitsPersistence\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo some students stop watching videos across term?"
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#multiple-views",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#multiple-views",
    "title": "Math Biology Video Project",
    "section": "Multiple Views",
    "text": "Multiple Views\n\nQueryRPos CoeffNeg Coeff\n\n\nWhat influences students to view students multiple times?\n\n\n\n\n\nCall:\nglm(formula = multiple_plays ~ intrigue_cat + fun_cat + appeals_cat + \n    interesting_cat + valuable_cat + important_cat + essential_cat + \n    useful_cat + work_harder_cat + worry_cat + intimidate_cat + \n    easy_hard + complicated_simple + confusing_clear + comfortable_uncomfortable + \n    satisfying_frustrating + challenging_not_challenging + pleasant_unpleasant + \n    chaotic_organized + GPA + pct_math + video_length + video_number, \n    family = \"binomial\", data = df)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.3229  -0.9405  -0.4840   1.0090   2.2857  \n\nCoefficients: (1 not defined because of singularities)\n                              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                 -2.764e+00  1.859e+00  -1.487 0.137076    \nintrigue_catincrease         1.150e-01  1.302e+00   0.088 0.929576    \nintrigue_catdecrease         1.370e+00  1.173e+00   1.168 0.242842    \nfun_catincrease             -8.922e-01  5.231e-01  -1.705 0.088116 .  \nfun_catdecrease              2.311e+00  7.322e-01   3.156 0.001598 ** \nappeals_catincrease          2.869e-01  6.281e-01   0.457 0.647773    \nappeals_catdecrease         -1.698e+00  6.447e-01  -2.634 0.008434 ** \ninteresting_catincrease      1.707e+00  6.576e-01   2.595 0.009462 ** \ninteresting_catdecrease     -2.212e+00  4.147e-01  -5.334 9.62e-08 ***\nvaluable_catincrease        -1.199e+00  7.577e-01  -1.582 0.113597    \nvaluable_catdecrease        -1.618e+01  5.354e+02  -0.030 0.975895    \nimportant_catincrease       -8.767e-01  3.964e-01  -2.212 0.026967 *  \nimportant_catdecrease       -1.594e+01  5.354e+02  -0.030 0.976256    \nessential_catincrease       -3.513e-01  4.322e-01  -0.813 0.416374    \nessential_catdecrease        1.932e+01  5.354e+02   0.036 0.971210    \nuseful_catincrease           4.869e-01  4.568e-01   1.066 0.286416    \nuseful_catdecrease                  NA         NA      NA       NA    \nwork_harder_catincrease      2.774e-01  2.685e-01   1.033 0.301604    \nwork_harder_catdecrease     -2.725e-01  4.216e-01  -0.647 0.517945    \nworry_catincrease            5.338e-01  3.500e-01   1.525 0.127149    \nworry_catdecrease            9.584e-01  3.564e-01   2.689 0.007159 ** \nintimidate_catincrease      -1.419e+00  4.625e-01  -3.068 0.002155 ** \nintimidate_catdecrease      -1.469e+00  3.275e-01  -4.485 7.28e-06 ***\neasy_hard3                   1.374e+00  7.488e-01   1.834 0.066603 .  \neasy_hard4                   2.940e-01  7.214e-01   0.408 0.683598    \neasy_hard5                   1.593e+00  7.100e-01   2.243 0.024890 *  \neasy_hard6                  -3.706e-01  8.303e-01  -0.446 0.655323    \neasy_hard7                  -1.694e-01  1.037e+00  -0.163 0.870239    \ncomplicated_simple          -6.506e-01  1.773e-01  -3.671 0.000242 ***\nconfusing_clear              2.877e-01  1.620e-01   1.776 0.075785 .  \ncomfortable_uncomfortable   -3.927e-01  1.298e-01  -3.026 0.002476 ** \nsatisfying_frustrating       2.317e-01  1.159e-01   1.999 0.045608 *  \nchallenging_not_challenging -1.322e-01  1.641e-01  -0.805 0.420689    \npleasant_unpleasant          7.729e-01  1.475e-01   5.239 1.62e-07 ***\nchaotic_organized            3.058e-01  9.865e-02   3.100 0.001935 ** \nGPA                          2.159e-01  4.056e-01   0.532 0.594511    \npct_math                    -3.338e-03  3.305e-03  -1.010 0.312373    \nvideo_length                 1.076e-04  1.861e-04   0.578 0.563013    \nvideo_number                -4.326e-02  1.217e-02  -3.555 0.000378 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1198.6  on 867  degrees of freedom\nResidual deviance: 1000.0  on 830  degrees of freedom\n  (1089 observations deleted due to missingness)\nAIC: 1076\n\nNumber of Fisher Scoring iterations: 12\n\n\n\n\nViewing multiple times is encouraged by\n\nIt is fun (decrease) to use math to understand biology\nUsing math to understand biology is interesting (increase)\nI worry (decrease) about getting worse grades in a biology course that incorporates math than one that does not\npleasant versus unpleasant\nchaotic versus organized\n\n\n\nViewing multiple times is discouraged by\n\nUsing math to understand biology appeals (decrease) to me\nUsing math to understand biology is interesting (decrease)\nIt is important (increase) for me to be able to do math for my career in the life sciences\nTaking a biology course that incorporates math intimidates (both) me\ncomplicated versus simple\ncomfortable versus uncomfortable\nsatisfying versus frustrating\ntime in semester (video number)"
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#viewing-time",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#viewing-time",
    "title": "Math Biology Video Project",
    "section": "Viewing Time",
    "text": "Viewing Time\n\nQueryRPos CoeffNeg Coeff\n\n\nWhat influences students to spend more time watching the videos?\n\n\n\n\n\nCall:\nglm(formula = as.numeric(avg_view_time_when_played) ~ intrigue_cat + \n    fun_cat + appeals_cat + interesting_cat + valuable_cat + \n    important_cat + essential_cat + useful_cat + work_harder_cat + \n    worry_cat + intimidate_cat + easy_hard + complicated_simple + \n    confusing_clear + comfortable_uncomfortable + satisfying_frustrating + \n    challenging_not_challenging + pleasant_unpleasant + chaotic_organized + \n    GPA + pct_math + video_length + video_number, family = \"gaussian\", \n    data = df)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-853.86  -128.02   -24.41   108.91  1139.41  \n\nCoefficients: (1 not defined because of singularities)\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  180.5561   176.8864   1.021 0.307672    \nintrigue_catincrease         153.1457   116.2658   1.317 0.188134    \nintrigue_catdecrease         328.5588   104.4253   3.146 0.001712 ** \nfun_catincrease                2.3447    48.3834   0.048 0.961360    \nfun_catdecrease              -40.4265    74.1309  -0.545 0.585667    \nappeals_catincrease          -22.9577    56.2257  -0.408 0.683149    \nappeals_catdecrease           28.4891    66.2874   0.430 0.667466    \ninteresting_catincrease       85.8513    60.3164   1.423 0.155011    \ninteresting_catdecrease       -6.5632    41.9026  -0.157 0.875575    \nvaluable_catincrease        -153.6194    72.3949  -2.122 0.034136 *  \nvaluable_catdecrease        -872.1688   246.4276  -3.539 0.000424 ***\nimportant_catincrease        -16.3917    39.5645  -0.414 0.678758    \nimportant_catdecrease       -842.0904   255.4479  -3.297 0.001020 ** \nessential_catincrease         78.0939    41.2858   1.892 0.058900 .  \nessential_catdecrease        826.7246   268.3537   3.081 0.002133 ** \nuseful_catincrease           -28.3670    41.7338  -0.680 0.496876    \nuseful_catdecrease                 NA         NA      NA       NA    \nwork_harder_catincrease      -14.9730    27.3546  -0.547 0.584274    \nwork_harder_catdecrease       36.4671    38.6517   0.943 0.345711    \nworry_catincrease             13.4219    37.2188   0.361 0.718474    \nworry_catdecrease             -2.8790    35.4262  -0.081 0.935249    \nintimidate_catincrease        -2.7321    45.7014  -0.060 0.952344    \nintimidate_catdecrease        33.5371    32.8474   1.021 0.307552    \neasy_hard3                   -34.3803    74.1131  -0.464 0.642848    \neasy_hard4                   -25.4733    71.6178  -0.356 0.722167    \neasy_hard5                   -26.0246    69.5317  -0.374 0.708289    \neasy_hard6                  -100.2542    82.3422  -1.218 0.223748    \neasy_hard7                   221.9490    96.7221   2.295 0.021999 *  \ncomplicated_simple           -21.7275    17.1182  -1.269 0.204705    \nconfusing_clear               31.3572    16.0778   1.950 0.051472 .  \ncomfortable_uncomfortable     28.3085    13.1634   2.151 0.031801 *  \nsatisfying_frustrating       -20.8471    12.0115  -1.736 0.083008 .  \nchallenging_not_challenging  -17.2412    16.4447  -1.048 0.294744    \npleasant_unpleasant           -0.3234    14.5043  -0.022 0.982217    \nchaotic_organized            -19.1039     9.7751  -1.954 0.050996 .  \nGPA                           61.4313    39.0669   1.572 0.116225    \npct_math                       0.1931     0.3323   0.581 0.561199    \nvideo_length                   0.2106     0.0188  11.204  < 2e-16 ***\nvideo_number                   3.1522     1.2089   2.607 0.009288 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 51216.36)\n\n    Null deviance: 59330647  on 867  degrees of freedom\nResidual deviance: 42509579  on 830  degrees of freedom\n  (1089 observations deleted due to missingness)\nAIC: 11915\n\nNumber of Fisher Scoring iterations: 2\n\n\n\n\nViewing time is encouraged by\n\nUsing math to understand biology intrigues (decrease) me\ncomfortable versus uncomfortable\ntime in semester (video number)\n\n\n\nViewing time is discouraged by\n\nMath is valuable (both) for me for my life science career\nIt is important (decrease) for me to be able to do math for my career in the life sciences"
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#take-home-messages",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#take-home-messages",
    "title": "Math Biology Video Project",
    "section": "Take Home Messages",
    "text": "Take Home Messages\nStudents who viewed videos multiple times and/or for longer duration were\n\nmore pessimistic about math emotions\nworried less about their course grade\nnot affected by the proportion of math content"
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html#thank-you",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html#thank-you",
    "title": "Math Biology Video Project",
    "section": "Thank You",
    "text": "Thank You\n\n\nDerek Sollberger\n\nData Analyst\nUC Merced\ndsollberger@ucmerced.edu\n\n\nDr Emily Weigel\n\nCourse Instructor\nGeorgia Tech\nemily.weigel@biosci.gatech.edu"
  },
  {
    "objectID": "posts/xDBER/Sollberger_X_DBER_slides.html",
    "href": "posts/xDBER/Sollberger_X_DBER_slides.html",
    "title": "Math Biology Video Project",
    "section": "",
    "text": "Derek Sollberger\n\nData Analyst\nUC Merced\n\n\nDr Emily Weigel\n\nCourse Instructor\nGeorgia Tech\n\n\n\n\n\n\n\n\nEcology course (prereq: Intro Bio)\nFall 2018 semester\n91 students (85 students in study)\n24 videos\n\nabout 10 minutes per video\n\n\n\n\n\n\nimage credit: Shutterstock\n\n\n\n\n\n\n\n\n\n\n\n\nmath background\n\n\n\n\nmostly sophomores\nprior experience in flipped classrooms\nmostly White and Asian students\n77 percent female\n\n\n\n\n\n\n\nValuesValues 2EmotionsEmotions 2\n\n\n\n\n\nAndrews 2017\n\n\n\n\n\n\n\nMath Biology Values Instrument\n\n\n\n\n\n\n\nWachsmuth 2017\n\n\n\n\n\n\n\nMath Emotions Instrument\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur first glance at the survey data showed no significant results between the pre and post surveys.\n\n\n\nWe grouped students into “unchanged”, “increase”, or “decrease” groups based on their pre- and post-semester survey results for the MBVI queries—where “unchanged” was a difference of -1, 0, or 1 on the 7-point Likert scales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne VideoAll Videos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMath Biology Values Instrument\n\n\n\n\n\n\n\n\n\n\n\n\nPlaysVisitsPersistence\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo some students stop watching videos across term?"
  },
  {
    "objectID": "posts/sex_bio_context/sex_in_a_biological_context.html",
    "href": "posts/sex_bio_context/sex_in_a_biological_context.html",
    "title": "Sex in a Biological Context",
    "section": "",
    "text": "Goal\n\nEncourage students to use established research materials to explore sex in a biological context\n\nObjectives\n\nComment on an interview with Dr Joan Roughgarden\nSummarize a passage from a book by Dr Joan Roughgarden\nInterpret a couple pieces of data visualizaton from sex studies\n\nContext\n\ndata science course\nmostly biology majors, mostly sophomores\nhomework assignment\n\n\n\n\n\nTaskWord CloudSample Responses\n\n\n\n\nDr Joan Roughgarden was one of the most important researchers in the field of sexual selection theory, and she has written several works on the matters including the book Evolution’s Rainbow. Dr Roughgarden spoke at a WiSE conference (Women in Science and Engineering) a couple of years ago. For this resource , you may focus on the middle of the video from the “Evolution’s Rainbow” segment (at the 9:25 mark) to the “Career track” segment (at the 15:50 mark).\n\nhttps://www.youtube.com/watch?v=hDbsQu0XhPo\nsource: https://www.wisecology.net/speakers/joan-roughgarden/\n\n\n\n\n\nDr Joan Roughgarden\n\n\n\n\n\n\n\n\n\nresponses to the video interview\n\n\n\n\n\n“There is a lot of diversity in sex and gender in not only humans, but animals as well. With a variety of sex and gender in living beings that is identified by Dr. Roughgarden, it may mean that the sexual selection theory is outdated as we expand our knowledge on this topic. The theory needs to be rewritten for this modern era.”\n\n“This excerpt from Dr. Joan Roughgarden discusses her work on her book Evolution’s Rainbow and her personal experience as a (trans) woman in science. She discusses her work on gender and sexuality across all animal kingdoms, argues that sexual selection should be scrapped, and thinks it will collapse altogether. As a woman in science, she has seen that men’s careers in science are linear and are privileged with a sense of authority.”\n“The career track segment of Dr. Joan Roughgarden’s speech at the Women in Science and Engineering conference focused on her experiences as a transgender woman in the field of biology. She shared the challenges she faced while navigating her gender identity in a male-dominated field and the discrimination and bias she encountered. However, she also emphasized the importance of being true to oneself and finding a supportive community. Roughgarden’s message was one of resilience and perseverance in the face of adversity.”\n\n\n\n\n\n\n\n\nTaskWord CloudSample Responses\n\n\n\n\nSkim through chapter 2 “Sex versus Gender” of Evolution’s Rainbow. What is your impression of the writing? Or, what information did you get from this chapter?\n\n\n\n\nEvolution’s Rainbow\n\n\n\n\n\n\n\n\n\nresponses to the book excerpt\n\n\n\n\n\n“While reading the small passage, from Evolution’s Rainbow Chapter 2, it states that male and female are just biological categories. It starts by saying that people use the words, gender and sex wrong stating that the word’s mean male and female. In which the word’s male and female does not relate with have two different meanings biological criteria and in the social criteria.”\n“Looking through the text and readings we can see that Dr. Roughgarden discusses in terms about”male” and “female” instead of “man” and “woman”. As she done so she also discusses about when it comes to humans male and female don’t coincide 100 percent. She also discusses about the social categories rests in society and not in science.”\n\n“This excerpt approaches males and females from the sex, gender, and social perspective. It states that male and female as a \"Sex\" does not make sense since sex refers to the mixing of genes or reproduction, but some reproduction is asexual reproduction without two partners. Gender’s definition is embracing the biological definition but the other attributes of gender –masculinity and femininity– are not defined biologically. The author is writing up and tearing down these words and stripping them of meaning to reveal their inconsistencies.”\n\n\n\n\n\n\n\n\nTask (3)Word Cloud (3)Sample Responses (3)Task (4)Word Cloud (4)Sample Responses (4)\n\n\n\n\nWhat is your impression of the data visualization below? What information can you gather from the figure(s)?\n\nManey DL, Merritt JR, Prichard MR, Horton BM, Yi SV. Inside the supergene of the bird with four sexes. Horm Behav. 2020 Nov;126:104850. doi: 10.1016/j.yhbeh.2020.104850. Epub 2020 Sep 19. PMID: 32937166; PMCID: PMC7725849.\n\n\n\n\nData Viz 1\n\n\n\n\n\n\n\n\n\nresponses to the first graph\n\n\n\n\n\n“One morph performs a few of the aforementioned actions more frequently than the other. For instance, both sexes of WS birds sing more frequently in response to simulated territorial invasions than TS birds do. TS females seldom ever sing, despite the fact that TS males frequently sing loudly. While TS males are more likely to stay in their own territories, WS males are more prone to participate in territorial invasions. TS birds provide nestlings more frequently than their WS counterparts, and males reproduce this tendency more frequently than females. In general, WS birds appear to devote more time to mate-hunting and intrasexual rivalry, whereas TS birds adopt a more parental life-history approach.”\n\n“that data infomration that has been provided above has allowed me to follow what is being studied fairly easy since they would use the the color of the birds that they have to be distinguished and is being used in the boxplots in which helps us know which one is for which. with that in mind the boxplot allows us to understand the ranges that they have within the species while also allowing us to see how long the songs that each of the birds would sing within the ranges of ten minutes which shows us how different they are. while within the other boxplot then they would show the trips per hour in which helps us see how different they are compared the sexes from both of the species since the females TS have the highest trips per hour compared to the others. another thing they would use is the means, medians, and the quartiles so that they could be compared between the species and their sexes to know the differences.”\n“I can see that the tan-striped bird makes more trips but they have shorter songs sung. Compared to the white bird he made fewer trips but sang for longer times than the tan-striped bird. The used a box graph to show the difference.”\n\n\n\n\n\nWhat is your impression of the data visualization below? What information can you gather from the figure(s)?\n\nManey DL, Merritt JR, Prichard MR, Horton BM, Yi SV. Inside the supergene of the bird with four sexes. Horm Behav. 2020 Nov;126:104850. doi: 10.1016/j.yhbeh.2020.104850. Epub 2020 Sep 19. PMID: 32937166; PMCID: PMC7725849.\n\n\n\n\nData Viz 2\n\n\n\n\n\n\n\n\n\nresponses to the second graph\n\n\n\n\n\n“Prolactin has been associated with provisioning behaviors in both male and female songbirds. Females had a higher normalized VIP expression. Song rate is much higher in males.”\n\n“My impression of the data visualization is that is clear to follow, the colors are coordinated and it has just the necessary information. From the figures it can be gathered that WS have a higher VIP expression compared to that of the TS, also that TS females have a shorter range than all the other birds. Then from figures C and D we can observe whether there is correlation between the song rate and the VIP expression. For males there is no correlation but for females there is a slight positive correlation.”\n“The males of different markings have more differences to each other than the male and female of similar markings when looking at songs produced. Adding hormones into the mix helped condense the songs between birds of similar markings, making the plot a lot less scattered.”\n\n\n\n\n\n\n\n\nTaskSample Responses\n\n\n\n\nIf you wanted to discuss the topic of sex (and maybe gender) in a biological context, what other information would you seek out?\n\n\n\n\nresponses to the last prompt\n\n\n\n\n\n\n\n“If I would want to broaden my understanding on this topic, which is something that I will definitely be looking for, is probably toward podcasts and other articles can help me better understand the difference between sex and gender from there experiences.”\n“What are the biological factors of sex? Does mental health come into play?”\n“I would seek out more information on the genetic compositions of organisms and specifically compare genetic maps of female and male organisms. I would also look at asexual organisms and study how reproduction happens with an organism that is neither female nor male or an organism that is both. We could also study the chemicals released on organisms based on gender like how testosterone is released in male organisms and estrogen is released in female organisms.”"
  },
  {
    "objectID": "posts/graphviz/graphviz.html",
    "href": "posts/graphviz/graphviz.html",
    "title": "graphviz",
    "section": "",
    "text": "For years, I have been searching for the ability to make color-coded flowcharts, and I have found “graphviz online!”. We can use apps such as this one.\nThe code is very intuitive and easy to use. Furthermore, there are many attribute options for nodes and edges.\ndigraph G {\n\n\"Egg\" -> \"Fried\\nEgg\"\n\"Potato\" -> \"Hashbrowns\"\n\"Oil\" -> \"Hashbrowns\"\n\"Egg\" -> \"Pancakes\"\n\"Wheat\\nFlour\" -> \"Pancakes\"\n\n\"Fried\\nEgg\" -> \"Complete\\nBreakfast\"\n\"Hashbrowns\" -> \"Complete\\nBreakfast\"\n\"Milk\" -> \"Complete\\nBreakfast\"\n\"Pancakes\" -> \"Complete\\nBreakfast\"\n\n\n\"Egg\" [shape = circle, style = filled, fillcolor = \"#59C9F1\"]\n\"Potato\" [shape = circle, style = filled, fillcolor = \"#59C9F1\"]\n\"Oil\" [shape = square, style = filled, fillcolor = \"#DDA059\"]\n\"Wheat\\nFlour\" [shape = circle, style = filled, fillcolor = \"#59C9F1\"]\n\n\"Fried\\nEgg\" [shape = square, style = filled, fillcolor = \"#DDA059\"]\n\"Milk\" [shape = circle, style = filled, fillcolor = \"#59C9F1\"]\n\"Hashbrowns\" [shape = square, style = filled, fillcolor = \"#DDA059\"]\n\"Pancakes\" [shape = square, style = filled, fillcolor = \"#DDA059\"]\n\"Complete\\nBreakfast\" [shape = hexagon, style = filled, fillcolor = \" #FFD921\"]\n}\n\n\n\nStardew Valley complete breakfast"
  },
  {
    "objectID": "posts/SpatialDataNotes/04_spherical-geometries.html",
    "href": "posts/SpatialDataNotes/04_spherical-geometries.html",
    "title": "The Median Data Scientist",
    "section": "",
    "text": "Learning objectives:\n\nConsider geometries on a sphere\n\n\n\n\nTriangle on a Globe\n\n\n\nlibrary(\"dplyr\")\nlibrary(\"ggplot2\")\nlibrary(\"maps\")\nlibrary(\"rnaturalearth\")\nlibrary(\"rnaturalearthdata\")\nlibrary(\"s2\")\nlibrary(\"sf\")\n\nsessionInfo()\n\nR version 4.2.2 (2022-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19044)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] sf_1.0-12               s2_1.1.3                rnaturalearthdata_0.1.0\n[4] rnaturalearth_0.3.2     maps_3.4.1              ggplot2_3.4.2          \n[7] dplyr_1.1.2            \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.10        pillar_1.9.0       compiler_4.2.2     class_7.3-20      \n [5] tools_4.2.2        digest_0.6.31      lattice_0.20-45    jsonlite_1.8.4    \n [9] evaluate_0.21      lifecycle_1.0.3    tibble_3.2.1       gtable_0.3.3      \n[13] pkgconfig_2.0.3    rlang_1.1.0        cli_3.6.0          DBI_1.1.3         \n[17] rstudioapi_0.14    xfun_0.39          fastmap_1.1.1      e1071_1.7-13      \n[21] withr_2.5.0        httr_1.4.5         knitr_1.42         generics_0.1.3    \n[25] vctrs_0.6.1        htmlwidgets_1.6.2  classInt_0.4-9     grid_4.2.2        \n[29] tidyselect_1.2.0   glue_1.6.2         R6_2.5.1           fansi_1.0.4       \n[33] rmarkdown_2.21     sp_1.6-0           magrittr_2.0.3     units_0.8-2       \n[37] scales_1.2.1       htmltools_0.5.4    colorspace_2.1-0   KernSmooth_2.23-20\n[41] utf8_1.2.3         proxy_0.4-27       wk_0.7.3           munsell_0.5.0     \n\n\n\n\n\n\nHow does the GeoJSON format (Butler et al. 2016) define “straight” lines between ellipsoidal coordinates (Section 3.1.1)? Using this definition of straight, how does LINESTRING(0 85,180 85) look like in an Arctic polar projection? How could this geometry be modified to have it cross the North Pole?\n\n\n\nthis_linestring <- st_linestring(matrix(c(0, 85, 180, 85), ncol = 2),\n                                 dim = \"XY\")\nclass(this_linestring)\n\n[1] \"XY\"         \"LINESTRING\" \"sfg\"       \n\n\n\n\n\n\nthis_linestring |>\n  ggplot() +\n  geom_sf(color = \"red\", linewidth = 3) +\n  labs(title = \"This Linestring\",\n       subtitle = \"Where is it?\",\n       caption = \"Spatial Data Science book club\") +\n  theme_minimal()\n\n\n\n\n\n# https://stackoverflow.com/questions/58919102/map-arctic-subarctic-regions-in-ggplot2-with-lambert-conformal-conic-projection\nworld <- ne_countries(scale = \"medium\", returnclass = \"sf\")\nworld_cropped <- world |>\n  st_make_valid() |>\n  st_crop(xmin = -180.0, xmax = 180.0, ymin = 45.0, ymax = 90.0)\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n# st_sfc(this_linestring) <- st_crs(world_cropped)\n\n# this_linestring_sf <- st_sf(this_linestring, \n#                             st_sfc(this_linestring, crs = \"EPSG:3995\"))\n\nggplot(data = world_cropped) + \n  geom_sf() + \n  # geom_sf(data = this_linestring, color = 'red') +\n  coord_sf(crs = \n             \"+proj=lcc +lat_1=50 +lat_2=70 +lat_0=40 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0\")\n\n\n\n\n\n\n\nFor a typical polygon on \\(S^2\\), how can you find out ring direction?\n\nA convention here is to define the inside as the left (or right) side of the polygon boundary when traversing its points in sequence. Reversal of the node order then switches inside and outside.\nAdditional resource: ESRI: Polygon page\n\n\n\n\n\nAntarctica_map <- map(fill = TRUE, plot = FALSE) |>\n  st_as_sf() |>\n  filter(ID == \"Antarctica\")\n\nAntarctica_map |> \n  ggplot() + \n  geom_sf() +\n  labs(title = \"Antarctica\", \n       subtitle = \"Think of the latitude\",\n       caption = \"Spatial Data Science book club\")\n\n\n\n\n\nst_bbox(Antarctica_map)\n\n      xmin       ymin       xmax       ymax \n-180.00000  -85.19218  179.62032  -60.52090 \n\n\nwhich clearly does not contain the region (ymin being -90 and xmax 180).\n\nFiji_map <- map(fill = TRUE, plot = FALSE) |>\n  st_as_sf() |>\n  filter(ID == \"Fiji\")\n\nFiji_map |> \n  ggplot() + \n  geom_sf() +\n  labs(title = \"Fiji\", \n       subtitle = \"Think of the longitude\",\n       caption = \"Spatial Data Science book club\")\n\n\n\n\n\nst_bbox(Fiji_map)\n\n      xmin       ymin       xmax       ymax \n-179.86734  -21.70586  180.17769  -12.47695 \n\n\nseems to span most of the Earth\n\n\n\ns2_bounds_cap(Antarctica_map)\n\n  lng lat   angle\n1   0 -90 29.4791\n\n\n\ns2_bounds_rect(Antarctica_map)\n\n  lng_lo lat_lo lng_hi   lat_hi\n1   -180    -90    180 -60.5209\n\n\n\ns2_bounds_rect(Fiji_map)\n\n    lng_lo    lat_lo    lng_hi    lat_hi\n1 174.5872 -21.70586 -178.2511 -12.47695\n\n\n\n\n\n\nMaps of Antarctica should probably display the South Pole. Do the following maps display the South Pole?\n\n\n\n# maps package\nm <- st_as_sf(map(fill=TRUE, plot=FALSE))\nAntarctica_map_A <- m[m$ID == \"Antarctica\", ]\nst_geometry(Antarctica_map_A) |>\n  ggplot() + \n  geom_sf() +\n  labs(title = \"Antarctica\", \n       subtitle = \"Think of the latitude\",\n       caption = \"Spatial Data Science book club\")\n\n\n\n\n\nsf::st_is_valid(Antarctica_map_A)\n\n[1] TRUE\n\n\n\n# Natural Earth package\nne <- ne_countries(returnclass = \"sf\")\nAntarctica_map_B <- ne[ne$region_un == \"Antarctica\", \"region_un\"]\nst_geometry(Antarctica_map_B) |>\n  ggplot() + \n  geom_sf() +\n  labs(title = \"Antarctica\", \n       subtitle = \"Think of the latitude\",\n       caption = \"Spatial Data Science book club\")\n\n\n\n\n\nsf::st_is_valid(Antarctica_map_B)\n\n[1] TRUE\n\n\n\n\n\n\nAntarctica_map_C <- st_geometry(Antarctica_map_A) |>\n  st_transform(3031)\nAntarctica_map_C |> \n  ggplot() + \n  geom_sf() +\n  labs(title = \"Antarctica\", \n       subtitle = \"Think of the latitude\",\n       caption = \"Spatial Data Science book club\")\n\n\n\n\n\nsf::st_is_valid(Antarctica_map_C)\n\n[1] TRUE\n\n\n\nAntarctica_map_D <- st_geometry(Antarctica_map_B) |>\n  st_transform(3031)\nAntarctica_map_D |> \n  ggplot() + \n  geom_sf() +\n  labs(title = \"Antarctica\", \n       subtitle = \"Think of the latitude\",\n       caption = \"Spatial Data Science book club\")\n\n\n\n\n\nsf::st_is_valid(Antarctica_map_D)\n\n[1] TRUE\n\n\n\n\n\n\n\n\n\n\n\n\nMeeting chat log\n\nLOG"
  }
]