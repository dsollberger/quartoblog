---
title: "Processor Checks"
author: "Derek Sollberger"
date: "2025-06-22"
format:
  html
---

```{r}
#| message: false
#| warning: false


```


# Setting the Scene

For my machine learning class (with AI topics), I should survey the students to get a sense of how powerful their computers are.  In particular, I want to ask them

* How many CPUs does your computer have?
* Does your computer processing have accessing to GPUs?

For my own skills, I want to provide the code for these tasks in both `R` and `Python`.

# R

## How many CPUs does your computer have?

In `R`, we can use the `detectCores()` function from the `parallel` package for this task.

```{r}
print(paste0("The number of cores on my computer is: ",
             parallel::detectCores()))
```

Aside, upon looking up this function, I came across this neat [blog post](https://www.jottr.org/2022/12/05/avoid-detectcores/) that advises developers to avoid using `detectCores()` (i.e. don't use *all* of the users' CPUs).

## Does your computer processing have accessing to GPUs?

I have been moving to teaching in `PyTorch`, so I am familiar with `torch` packages.

```{r, eval = FALSE}
library("torch")
```

At the time of this writing, my CUDA version was higher than what the R `torch` package was compatibile with.

```{r, eval = FALSE}
# Check if CUDA is available
cuda_available = torch.cuda.is_available()

# Print the result
print(paste("CUDA available:", cuda_available))

# If CUDA is available, you can also print the number of GPUs
if (cuda_available) {
  print(paste("Number of GPUs available:", torch.cuda.device_count()))
  print(paste("GPU Name:", torch.cuda.get_device_name(0))) # Assuming at least one GPU
} else {
  print("CUDA is not available on this system.")
}
```


# Python

## How many CPUs does your computer have?

We can use the `cpu_count()` function from the `multiprocessing` library.

```{python}
import multiprocessing
print(multiprocessing.cpu_count())
```

## Does your computer processing have accessing to GPUs?

```{python, eval = FALSE}
import torch

if torch.cuda.is_available():
  print("GPU is available.")
else:
  print("GPU is not available.")
```

















::: {.callout-note collapse="true"}
## Session Info

```{r}
sessionInfo()
```
:::


:::: {.columns}

::: {.column width="45%"}
	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}

:::

::::

::::: {.panel-tabset}



:::::